# Отчёт: Лучшие практики инфраструктурной инженерии, DevOps и SRE (2023–2024)

## Введение

2023–2024 годы ознаменовались существенной эволюцией подходов к инфраструктурной инженерии, DevOps и Site Reliability Engineering (SRE). Организации стремятся повысить автоматизацию, устойчивость и наблюдаемость своих систем на всех типах инфраструктур – облачных (cloud-native), локальных (on-premises) и гибридных. В данном отчёте собраны **актуальные лучшие практики** этих лет, охватывающие новые техники (CI/CD, GitOps, IaC, Observability, fault-tolerance, disaster recovery и др.), инструменты, платформы, а также языки и фреймворки, используемые для управления инфраструктурой и обеспечением надёжности. Особый фокус делается на **open-source решениях**, которые занимают ведущие позиции, с упоминанием enterprise-решений лишь в случаях их инновационности или доминирования на рынке. Отмечены наиболее значимые **изменения 2023–2024 годов**, которые влияют на то, как современные команды проектируют и эксплуатируют сложные распределённые системы.

*(Примечание: В отчёте используются принятые сокращения: CI/CD – Continuous Integration/Continuous Delivery (непрерывная интеграция и доставка), IaC – Infrastructure as Code (инфраструктура как код), и т.д.)*

## Новые техники и подходы

### Непрерывная интеграция/доставка (CI/CD) и DevSecOps

**Автоматизация CI/CD** стала неотъемлемым фундаментом современного DevOps. Лучшие практики требуют максимально раннего и частого слияния кода и развертывания изменений небольшими порциями. В 2023–2024 годах продолжилась тенденция к внедрению *“everything as code”* – конфигурации конвейеров сборки/развертывания описываются декларативно (например, YAML-пайплайны в GitLab CI, GitHub Actions), что упрощает повторяемость и обзор изменений. Также усилилось внимание к **DevSecOps**, интеграции безопасности в цикл CI/CD: согласно отчёту GitLab 2024, безопасность стала приоритетом №1 в DevOps, даже опережая сами улучшения CI/CD ([Exploring Best Practices and Modern Trends in CI/CD - Blog | GitProtect.io](https://gitprotect.io/blog/exploring-best-practices-and-modern-trends-in-ci-cd/#:~:text=Let%E2%80%99s%20start%20with%20statistics%3A%20continuous,detect%20vulnerabilities%20and%20bugs%20earlier)). Практически это выражается во включении статического анализа кода, сканирования зависимостей и контейнеров на уязвимости на каждом шаге конвейера. Например, популярно использование open-source сканеров (Snyk, OWASP ZAP, Trivy и др.) на этапах сборки.

**Оркестрация релизов.** Для повышения надёжности выпуска обновлений в производство применяются техники *progressive delivery* – постепенные развертывания с контролем качества. Распространены шаблоны **blue-green deployment** (одновременное поддержание старой и новой версий с переключением трафика) и **canary releases** (постепенная отдача трафика на новую версию). Эти подходы стали проще благодаря инструментам: например, Argo Rollouts (дополнение к Argo CD) предоставляет готовые механизмы канареечных развертываний и отслеживания метрик, позволяя автоматически откатить релиз при деградации. Кроме того, всё чаще используются **feature flags** (флажки функциональности) для переключения фич без переразвертывания – open-source платформы вроде Unleash позволяют внедрять этот подход, снижая риски при выпуске изменений.

**Мониторинг конвейеров** – ещё одна практика, набравшая популярность. Речь идёт об наблюдаемости самих CI/CD-пайплайнов: метрики и логи сборочных агентов, время выполнения этапов, частота падений билдов. Современные команды внедряют дашборды *“Pipeline Health”*, чтобы выявлять узкие места и сбои в процессе доставки. Это коррелирует с общим движением к улучшению разработческого опыта: метрики эффективности (Lead Time, Deployment Frequency и пр. из DORA-метрик) стали постоянным объектом измерения. **Микросервисная архитектура** и containerization остаются важными факторами, влияющими на CI/CD – небольшие сервисы проще и быстрее проходить конвейер, а контейнеры обеспечивают единообразие среды от разработки до продакшена.

**Эпоха после Jenkins.** Хотя **Jenkins** по-прежнему широко используется, в 2023 году заметен сдвиг в сторону более облачно-родных и управляемых решений CI/CD. Многие организации мигрируют на встроенные конвейеры в платформах разработки: **GitLab CI/CD**, **GitHub Actions**, **Azure DevOps** – благодаря их глубокому интегрированию с репозиториями и удобству для разработчиков. Эти сервисы позволяют определять pipeline-as-code прямо рядом с кодом приложения. В то же время появляются cloud-native движки CI/CD: **Tekton** (CNCF) – фреймворк для конвейеров на Kubernetes, используемый “под капотом” в OpenShift Pipelines и др.; **Argo Workflows** – оркестратор CI/CD задач внутри кластера Kubernetes, позволяющий выстраивать сложные DAG’и задач (например, ML-пайплайны или обработка больших данных) в виде Kubernetes-ресурсов. Новые подходы лучше масштабируются и более тесно интегрируются со средой контейнеров, чем монолитный Jenkins. Тем не менее, Jenkins продолжает применяться для сложных кастомизированных сценариев и в консервативных средах, но считается *legacy*-вариантом, требующим дополнительной поддержки.

**DevSecOps и комплаенс.** В 2023–2024 практически обязательным элементом пайплайна стали этапы проверки соответствия политиками безопасности и соответствия (compliance). Инфраструктурные команды внедряют управление секретами и подпись артефактов: например, артефакты сборки (контейнеры, бинарные файлы) подписываются и верифицируются с помощью инструментов цепочки доверия (**Sigstore/cosign**), а для выпуска программ всё чаще формируются *Software Bill of Materials (SBOM)* – списки компонентов ПО для отслеживания уязвимостей. Эти практики стимулируются как требованиями отрасли, так и государственными регуляциями. Таким образом, *pipeline* современного предприятия включает не только сборку и деплой, но и встроенные **проверки безопасности, качества и готовности к восстановлению**, прежде чем изменение попадёт в продакшн.

### GitOps и непрерывное развертывание

За последние два года **GitOps** укрепился как стандарт де-факто для управления развертываниями и инфраструктурой. Суть подхода – хранение всей конфигурации системы (будь то манифесты Kubernetes или описания инфраструктуры) в системе контроля версий (Git) и автоматическое применение изменений из Git на окружения. К 2023 году GitOps вышел из разряда экспериментальных практик и стал массовым: опрос CNCF в 2023 показал, что *100% опрошенных компаний планируют внедрить GitOps в ближайшие 6–24 месяца*, а сами принципы GitOps объявлены **новым мейнстримом** ([GitOps goes mainstream - Flux CD boasts largest ecosystem | CNCF](https://www.cncf.io/blog/2023/12/01/gitops-goes-mainstream-flux-cd-boasts-largest-ecosystem/#:~:text=Takeaway%20%E2%80%93%20GitOps%20is%20the,Mainstream%20Standard%20in%202023)).

Основные преимущества GitOps – это **обратимость и прозрачность** изменений. Любое обновление конфигурации производится коммитом, который проходит код-ревью и фиксируется в истории; откат системы к предыдущему состоянию сводится к возврату Git-коммита. Кроме того, GitOps-операторы постоянно следят за дрейфом: если фактическое состояние кластера расходится с описанным в репозитории, оно автоматически приводится в соответствие (или уведомляет инженеров). Такая модель повышает надёжность изменений и снижает долю ручных операций.

**Инструменты GitOps.** Лидирующими open-source инструментами стали **Argo CD** и **FluxCD** – оба проекта достигли зрелости (Flux 2.0 GA релиз в 2023). **Argo CD** получил широкое признание за удобный веб-интерфейс и визуализацию состояния кластера; согласно опросу пользователей, 93% респондентов запускали Argo CD в production-средах, что подтверждает его надёжность на практике ([Argo CD & Rollouts 2023 User Survey Results | by Katie Lamkin | Argo Project](https://blog.argoproj.io/cncf-argo-cd-rollouts-2023-user-survey-results-514aa21c21df#:~:text=Argo%20CD%20has%20made%20significant,organizations%20easily%20achieve%20their%20goals)). **FluxCD** славится модульностью и гибкостью – он зачастую *встроен* в другие платформы: к примеру, GitLab в 2023 выбрал Flux в качестве стандартного встроенного механизма GitOps в своем продукте ([GitOps goes mainstream - Flux CD boasts largest ecosystem | CNCF](https://www.cncf.io/blog/2023/12/01/gitops-goes-mainstream-flux-cd-boasts-largest-ecosystem/#:~:text=Another%20really%20interesting%20aspect%20of,Azure%20Arc%2C%20Tanzu%20and%C2%A0EKS%20Anywhere)), аналогично Azure (через Azure Arc) и даже Kubernetes-дистрибутив EKS Anywhere от AWS включают FluxCD из коробки. Благодаря этому экосистема Flux стала очень обширной – он интегрируется с Helm, Terraform, Pulumi, Kubernetes Operator и другими инструментами ([GitOps goes mainstream - Flux CD boasts largest ecosystem | CNCF](https://www.cncf.io/blog/2023/12/01/gitops-goes-mainstream-flux-cd-boasts-largest-ecosystem/#:~:text=Anywhere%20anywhere)), что позволяет использовать единый подход GitOps для разнообразных ресурсов.

Оба решения, Argo и Flux, поддерживают многокластерные развертывания и масштабирование до тысяч приложений. Выбор между ними часто зависит от требований: Argo CD удобен для визуализации и командной работы, Flux – для встраивания в уже существующие потоки и при ориентации на Kubernetes-API. Многие организации даже используют их совместно (проект **Flamingo** объединяет UX Argo с механизмами Flux ([GitOps goes mainstream - Flux CD boasts largest ecosystem | CNCF](https://www.cncf.io/blog/2023/12/01/gitops-goes-mainstream-flux-cd-boasts-largest-ecosystem/#:~:text=the%C2%A0standard%20built,Azure%20Arc%2C%20Tanzu%20and%C2%A0EKS%20Anywhere))). Таким образом, в 2023–2024 **GitOps окончательно перешёл в разряд лучшей практики** для облачно-родных систем, обеспечивая сочетание непрерывной доставки с безопасностью и отслеживаемостью изменений.

Важно, что принципы GitOps начинают распространяться и за пределы Kubernetes. Например, подход *Terraform GitOps* подразумевает автоматический запуск Terraform-скриптов при изменениях в Git (с помощью инструментов типа Terraform Cloud/Enterprise, Atlantis и пр.), хотя классический Terraform не работает по модели непрерывного reconciliation. Тем не менее, концепция «**Git как единый источник правды**» применяется сейчас и к конфигурации инфраструктуры в широком смысле. Это сближает процессы разработки приложений и их инфраструктурного обеспечения.

### Инфраструктура как код (IaC) и управляемая конфигурация

**Infrastructure as Code (IaC)** утвердилась как стандарт управления инфраструктурой: вместо ручной настройки серверов и сервисов всё описывается декларативно в виде кода, который может быть версионирован, протестирован и автоматически применён. В 2023 году рынок решений IaC продолжил расти быстрыми темпами (с прогнозом увеличения с ~$0.8 млрд в 2022 до $2.3 млрд к 2027 ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=The%20market%20for%20Infrastructure%20as,as%20specialized%20providers%20like%20Hashicorp))), что отражает востребованность данного подхода.

Доминирующим инструментом остаётся **Terraform** – универсальный движок от HashiCorp для декларативного управления ресурсами в облаках и on-premise средах. Terraform поддерживает сотни провайдеров (AWS, Azure, GCP, Kubernetes, VMware и т.д.), что делает его “швейцарским ножом” для инфраструктурных команд. Большая экосистема модулей и сообщество из десятков тысяч пользователей и компаний подтверждают его популярность (по данным Enlyft, Terraform используют свыше 43 тысяч компаний ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=Its%20popularity%20is%20evident%20with,ranging%20applications))). Terraform выгодно выделяется агностичностью к платформе и выразительным декларативным синтаксисом (HCL). Он легко интегрируется в CI/CD конвейеры и поддерживает идеи GitOps через автоматизацию планирования и применения изменений ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=4,Terraform%E2%80%99s%20community%20actively%20contributes%20to)).

**Ключевое событие 2023 года** – изменение лицензии Terraform. В августе 2023 HashiCorp перевёл Terraform с открытой MPL 2.0 на собственную Business Source License (BSL), фактически перестав распространять актуальные версии как open-source ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=HashiCorp%20License%20Change%20%2F%20OpenTofu)). Это вызвало негативную реакцию сообщества ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=On%20August%2010th%2C%202023%2C%20HashiCorp,is%20managed%20by%20the%20Linux)) и в ответ породило форк **OpenTofu** (ранее известный как OpenTF) – открытый проект под эгидой Linux Foundation, продолжающий развитие Terraform v1.5 на свободной лицензии. Таким образом, на конец 2024 сложилась двоякая ситуация: Terraform остаётся самым зрелым IaC-инструментом, но его открытая версия застыла на релизе 1.5.x (и далее развивается как OpenTofu), а официальные новые версии от HashiCorp доступны под ограниченной лицензией. Многие организации рассматривают возможность перехода на OpenTofu, чтобы сохранить приверженность open-source, либо не обновляться выше 1.5.x. Данный случай подчёркивает важность открытости инструментария для инфраструктурной инженерии.

Помимо Terraform, набирают популярность и альтернативные подходы к IaC:

- **Pulumi** – платформа, позволяющая описывать инфраструктуру на полноценных языках программирования (TypeScript, Python, Go, C# и др.), вместо DSL. Преимущество Pulumi – разработчики могут использовать знакомые языки и инструменты (IDE, отладку, модули) для инфраструктурного кода ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=Pulumi%20offers%20developers%20a%20multi,contributing%20to%20its%20growing%20popularity)). Это упрощает сложную логику (циклы, условия) и интеграцию с логикой приложения. Pulumi активно развивается и поддерживает мульти-облако, однако он менее распространён, чем Terraform, и требует от инженеров навыков в языках программирования. В продакшн-средах Pulumi ценят за возможность создавать собственные абстракции и библиотеки для инфраструктуры, что особенно полезно в больших организациях, где инфраструктурный код усложняется.

- **Cloud Development Kits (CDK)** – фреймворки, похожие по идее на Pulumi, но привязанные к конкретным провайдерам. Например, **AWS CDK** (и аналогичные AWS SAM) позволяют описывать ресурсы AWS на TypeScript/Python/Java и затем генерировать CloudFormation-шаблоны для развертывания ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=AWS%20CloudFormation%20and%20AWS%20CDK)). Microsoft развивает язык **Bicep** для Azure (надстройка над ARM-шаблонами), а Google – **Kubernetes-based Config Connector** для своих сервисов. Эти инструменты снижают порог входа для разработчиков приложений в мир IaC, однако обычно применимы только в пределах соответствующей экосистемы (AWS, Azure и т.д.).

- **Kubernetes-ориентированные IaC:** Возникло новое направление – управление инфраструктурой через механизм Kubernetes. Проект **Crossplane** (CNCF) предоставляет *Universal Control Plane* – по сути, расширяет Kubernetes кастомными ресурсами для управления внешней инфраструктурой (вне самого кластера) ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=An%20open,to%20integrate%20directly%20with%20Kubernetes)). С Crossplane можно создавать в кластере объекты, описывающие, например, базы данных в AWS или виртуальные машины в vSphere – и Kubernetes контроллер сам будет создавать/обновлять эти внешние ресурсы, постоянно отслеживая их состояние. Такой *reconciliation*-подход (как у Kubernetes) понравился некоторым крупным пользователям: в 2023 сообщалось, что ряд европейских банков заменили Terraform на Crossplane, отметив ускорение развертываний за счёт асинхронной природы Crossplane и отсутствие длительных планировок зависимостей ([Banks dump Terraform for Crossplane infrastructure as code | TechTarget](https://www.techtarget.com/searchitoperations/news/366543172/Banks-dump-Terraform-for-Crossplane-infrastructure-as-code#:~:text=Upbound%27s%20Crossplane%20infrastructure%20as%20code,for%20asynchronous%20updates%20at%20scale)). Crossplane хорош для сценариев, когда нужна *платформенная* модель: платформа на базе Kubernetes предоставляет “инфраструктуру как сервис” для команд разработки, скрывая детали облачных API. Однако для простых случаев внедрение Crossplane может быть избыточным, требует компетенций по Kubernetes и ещё формирует best practices. Тем не менее, он уже считается **перспективной технологией**, особенно в контексте гибридных облаков (единый контроль за ресурсами в разных средах через знакомый API).

- **Конфигурационное управление и автоматизация:** Классические инструменты как **Ansible**, **Chef**, **Puppet** продолжают использоваться, хотя и несколько утратили популярность с развитием контейнеров и бессерверных сред. **Ansible** остаётся востребованным для управления конфигурацией ОС, развертывания на виртуальных машинах и сетевого оборудования, где агенты нежелательны – благодаря простоте (YAML-плейбуки) и отсутствию необходимости в постоянных агентских службах. В 2023 Ansible продвигает идею *Event-Driven Ansible* (реактивное выполнение задач по событиям) и теснее интегрируется с GitOps (проекты вроде ansible-runner, сочетание Ansible + Argo). Puppet/Chef используются в основном в легаси-инфраструктурах; новые проекты редко выбирают их, предпочитая комбинацию Terraform + Ansible или полностью контейнеризованные подходы.

- **Новые языки для IaC:** В 2023 появился любопытный эксперимент – **Winglang**, позиционирующийся как «язык программирования для облака» ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=Winglang)). Идея Wing – объединить код инфраструктуры и runtime-логику приложения в одном языке, компилируя затем в Terraform, CDK или JavaScript. Пока Wing находится в ранней стадии и применяется энтузиастами, но сам факт его появления отражает запрос сообщества на более гибкие средства IaC. Также в сообществе идут эксперименты с языками декларативной конфигурации нового поколения – **Cue**, **Dhall** – призванными упростить проверку и генерацию конфигураций (например, уменьшить риск ошибок в сложных YAML-файлах Kubernetes). Эти языки пока нишевые, но их интеграция в инструменты (Cue используется в проектах Istio, Kubernetes для генерации config’ов) дает основания считать их перспективными.

**Практики IaC.** Независимо от выбранных инструментов, к 2024 выработался ряд общепринятых практик: хранение инфраструктурного кода в репозиториях Git (рядом с приложением либо отдельно, но с прозрачными процессами ревью изменений); модульность и переиспользование (создание библиотек Terraform-модулей, Ansible-ролей и т.п., чтобы стандартизировать ресурсы); управление состоянием (Terraform state, например, хранят в удалённом бекенде с блокировкой, чтобы несколько инженеров не вносили конфликтных изменений); проверки и тестирование инфраструктурного кода (от статического анализа Terraform (tflint, checkov) до интеграционных тестов – например, используя Terratest для прогонки реального создания ресурсов в песочнице и последующей очистки). Всё это направлено на то, чтобы инфраструктура менялась **предсказуемо, контролируемо и с минимальным участием человека**.

### Наблюдаемость и мониторинг (Observability)

Сложность распределённых систем требует сильного фокуса на **наблюдаемости** – умении понимать внутренние состояния системы через собираемые сигналы. В 2023–2024 произошёл качественный скачок в области Observability: подходы стандартизируются, open-source инструменты доминируют, добавляются новые виды данных.

**Три столпа наблюдаемости** – метрики, логи и трассировки (traces) – теперь дополняются четвёртым: **профилирование**. *Непрерывное профилирование* (continuous profiling) стало доступнее благодаря инструментам вроде Parca и Grafana Phlare, позволяющим собирать профили CPU/памяти из продакшна с низкими накладными расходами и анализировать их наряду с другими метриками.

Самым значимым достижением 2023 года стало зрелость стандарта **OpenTelemetry (OTel)**. Проект OpenTelemetry объявил о достижении версии 1.0 и **стабильности ключевых компонентов** на KubeCon North America 2023 ([OpenTelemetry Announces General Availability | APMdigest](https://www.apmdigest.com/opentelemetry-announces-general-availability#:~:text=At%20KubeCon%20%2B%20CloudNativeCon%20North,0)). Это означает, что API и модели данных для трассировок, метрик и логов стабилизированы и поддерживаются SDK на основных языках (Java, .NET, Python, Go и др.) ([OpenTelemetry Announces General Availability | APMdigest](https://www.apmdigest.com/opentelemetry-announces-general-availability#:~:text=OpenTelemetry%20has%20stabilized%20its%20logging,NET%20SDKs)). OpenTelemetry объединяет ранее разрозненные решения – вместо использования разных агентов/библиотек для метрик (Prometheus client), для трассировок (OpenTracing/Jaeger) и логов, теперь есть **единый стандарт**. В результате вендоры массово поддерживают OTel: практически все крупные APM-платформы и open-source средства могут принимать или экспортировать данные в формате OpenTelemetry ([OpenTelemetry in 2023 - by Kevin Lin - Bit by Bit](https://bit.kevinslin.com/p/opentelemetry-in-2023#:~:text=OpenTelemetry%20in%202023%20,universal%20adoption%20among%20observability%20providers)). В 2024 году наблюдается рост нативного внедрения OTel в библиотеках и фреймворках приложений, что упрощает для SRE-инженеров задачу собрать полные сведения о работе сервисов.

**Open-source доминирует в наблюдаемости.** Согласно опросу Grafana Labs 2025, *75% организаций используют open-source решения для Observability*, причём **70% используют совместно Prometheus и OpenTelemetry** в том или ином виде ([OpenTelemetry Announces General Availability | APMdigest](https://www.apmdigest.com/opentelemetry-announces-general-availability#:~:text=Open%20source%20dominance%20continues%20in,both%20technologies%20for%20the%20second)). Это подтверждает, что связка Prometheus (метрики) + OTel (единый сбор данных) стала крайне популярной. **Prometheus** остаётся де-факто стандартом сбора метрик в облачно-родных системах: он прост в установке, имеет мощный язык запросов PromQL и огромный набор готовых экспортеров метрик. В 2023 вышли улучшения для масштабирования Prometheus – проект Prometheus усилил поддержку **разделения по зонам и реплик метрик**, а экосистемные решения вроде **Thanos, Cortex** позволяют строить горизонтально масштабируемые хранилища метрик на базе множества Prometheus-нод. Многие организации внедрили **алертинг на базе Prometheus Alertmanager** – описания правил алертов тоже хранятся как код, что соответствует принципам GitOps.

**Логирование** переживает переосмысление. Классические стеки типа **ELK** (Elasticsearch-Logstash-Kibana) или Splunk хоть и мощные, но дорого масштабируются. Поэтому набирают популярность более легковесные решения: **Grafana Loki** – система хранения логов, оптимизированная под формат меток Kubernetes; она не индексирует весь текст логов, а индексирует только метаданные (метки, теги), что снижает требования к ресурсам. Loki отлично интегрируется с Prometheus (концепция “метрики + логи” через общие метки) и Grafana для единого поиска. **OpenSearch** – открытый форк Elasticsearch – стал альтернативой для тех, кто хочет избегать лицензии Elastic; он развивает возможности поиска и аналитики логов под открытой лицензией. В 2023 open-source утилиты для логов (Beats, Fluentd/Fluent Bit) продолжили совершенствоваться, предлагая лучшую обработку и передачу логов с минимальной задержкой.

**Трассировка распределённых запросов** стала более практичной благодаря стабилизации OpenTelemetry. **Jaeger** (CNCF) и **Tempo** (от Grafana) – популярные open-source хранилища трейсов. Они позволяют связывать цепочки запросов через микросервисы, измерять время каждого шага и выявлять узкие места. В сочетании с метриками (метрики дают общую картину, а трейсы – детальную для конкретного запроса) это даёт полноценную наблюдаемость. Важным инструментом стал **OTel Collector** – универсальный агент/прокси, который может собирать метрики, логи, трейсы из разных источников (в том числе с помощью eBPF, о чём ниже) и пересылать их в нужное хранилище. С 2023 многие переходят на схему: приложение -> OTel SDK -> OTel Collector -> отправка в системы хранения (Prometheus, Loki, Jaeger или коммерческие APM). Это упрощает конфигурацию, так как Collector поддерживает **настройку как код** (Pipeline конфигурации в YAML) и позволяет гибко менять бекенды без модификации приложений.

**eBPF и телеметрия.** Всё шире используется технология **eBPF** (встраиваемые программы в ядре Linux) для наблюдаемости и безопасности. eBPF позволяет собирать метрики и трассировки прямо из ядра с минимальной нагрузкой на систему. В 2023 продолжился бум eBPF-решений: **Cilium** (CNCF) – сетевой плагин на eBPF – даёт детальную картину сетевого трафика и обеспечивает сетевую политику с малым оверхедом; **Pixie** (ныне часть New Relic) – eBPF-основанный инструмент для автоматического сбора трассировок и метрик с Kubernetes-кластеров без ручной модификации кода. Сам OpenTelemetry представил бета-версию автоматической инструментализации Go-приложений через eBPF, что снижает барьер внедрения наблюдаемости ([Announcing the Beta Release of OpenTelemetry Go Auto ...](https://www.cncf.io/blog/2025/03/03/announcing-the-beta-release-of-opentelemetry-go-auto-instrumentation-using-ebpf/#:~:text=Announcing%20the%20Beta%20Release%20of,observability%20best%20practices%20and)). Благодаря eBPF можно, например, отслеживать системные вызовы, параметры баз данных или профили ЦП прямо в продакшене, не меняя приложение. Лучшие практики рекомендуют аккуратно использовать eBPF (следить за версией ядра, правами запуска), но его потенциал для **глубокой и всеобъемлющей видимости** очевиден.

**Analytics и AIOps.** С ростом объёма телеметрии возникает задача интеллектуального анализа. В 2023 многие APM-вендоры включили элементы **ML/AI** для поиска аномалий в метриках, корреляции событий и даже предсказания инцидентов. Появился термин **AIOps** – применение искусственного интеллекта для операционных задач. Однако отношение к нему пока осторожное: по данным опроса SRE-специалистов, ~53% ожидают, что AI облегчит их работу в ближайшие два года, но практики разделились – руководство видит в AI способ оптимизации затрат, тогда как инженеры сомневаются и ценят возможность самим контролировать систему ([Navigating the SRE Landscape for 2024: A Comprehensive Exploration of Decentralized Practices | APMdigest](https://www.apmdigest.com/navigating-sre-landscape-2024-comprehensive-exploration-decentralized-practices#:~:text=Artificial%20intelligence%20)). Пока AI чаще используется для вспомогательных целей: автоматическая группировка алертов, рекомендация причин инцидента на основе прошлых данных, чат-боты для вопросов по документации. В производственных контурах решения полностью доверить управление AI ещё не относятся к best practice, скорее это экспериментальное направление.

**Наблюдаемость как код.** В русле Infrastructure as Code возникла концепция *Observability as Code*. Она предполагает, что все аспекты мониторинга и наблюдаемости (метрики, алерты, dashboards, SLO) описываются декларативно и хранятся в репозитории. Это предотвращает дрейф настройки мониторинга и упрощает её воссоздание. В 2023 появились инструменты для этого: **Grafana Tempo** и **Loki** имеют декларативные параметры для сбора, **Alertmanager** конфигурируется через YAML, а для графиков Grafana появилась возможность экспорта/импорта дашбордов в виде JSON, что затем отслеживается Git-ом (или использование Grafana Operator для Kubernetes). Спецификации вроде **OpenSLO** позволяют задавать SLO/SLI в виде YAML, а проекты (Sloth, например) генерируют на их основе Prometheus-алерты. Всё это помогает SRE-инженерам управлять надежностью с помощью кода так же, как DevOps управляют инфраструктурой.

### Отказоустойчивость и устойчивость к сбоям

Обеспечение **высокой доступности (High Availability)** и устойчивости к сбоям – краеугольный камень SRE. В 2023–2024 лучшие практики здесь получили дальнейшее развитие, отчасти под влиянием нескольких крупных инцидентов и повышенных ожиданий пользователей к непрерывности сервисов.

**Архитектурные паттерны высокой доступности.** В облачных развертываниях нормой является использование **нескольких зон доступности (AZ)**: приложения запускаются в кластере серверов, распределённом по разным физическим зонам одного региона, с балансировкой нагрузки. Это гарантирует работу при выходе из строя целого датацентра (AZ). Для критичных сервисов рекомендуется **мульти-региональное** развертывание (active-active в нескольких регионах), чтобы пережить сбой целого региона облака. Крупные компании всё чаще реализуют *active-active* архитектуры, где каждое географическое отделение способно автономно обслуживать пользователей ([Multi-Cloud Done Right: Patterns and Deployments | by Bijit Ghosh](https://medium.com/@bijit211987/multi-cloud-done-right-patterns-and-deployments-84684fe0d729#:~:text=Ghosh%20medium,Terraform)). Однако это очень сложные и дорогие решения – требуется распределённая синхронизация данных, глобальные балансировщики трафика, продуманная консистентность. Потому более распространён компромисс: один регион основной, другой – в режиме standby (active-passive) для аварийного переключения.

**Резервирование и репликация.** На уровне сервисов применяется репликация: базы данных запускаются в кластерах с репликами (master-standby или мульти-мастер), сервисы – минимум в двух экземплярах за load balancer. Компоненты без встроенной отказоустойчивости (например, очередь RabbitMQ, или сам компонент балансировщика) запускаются с избыточностью и механизмами перевыбора лидера. Best practice – не иметь *single point of failure*. В Kubernetes это обеспечивается контроллером ReplicaSet (поддерживает заданное количество pod’ов) и механикой **anti-affinity** (чтобы копии не оказались на одном узле). Вне Kubernetes также используются кластеры и кластерные менеджеры (Pacemaker, консенсус-алгоритмы и т.п.).

**Паттерны устойчивости в коде.** На уровне приложений популяризированы шаблоны **Circuit Breaker** (автоматическое отключение обращений к неисправному внешнему сервису, чтобы основной сервис не зависал) и **Bulkhead** (разделение потоков, чтобы сбой в одной части не “утопил” всю систему). Эти паттерны поддерживаются многими фреймворками (например, Hystrix, резилиентные вызовы в Spring Cloud, .NET Polly и пр.). В облачно-нативных средах эту логику часто перекладывают на **service mesh** – сетевые прокси могут автоматически ретраить запросы, ограничивать rate и разрывать соединения по таймауту. Таким образом, комбинируются меры на уровне инфраструктуры и приложений для достижения максимальной устойчивости.

**Chaos Engineering (инженерия отказов).** Существенное распространение получила практика *хаос-тестирования*: регулярное намеренное индуцирование отказов в системе, чтобы проверить её реакцию и обучить команды правильно реагировать. В 2023 это уже не экзотика, а почти мейнстрим среди крупных технологических компаний. Инструменты сделали хаос-инженерию доступнее: open-source **LitmusChaos** и **Chaos Mesh** позволяют задавать сценарии (поднять потребление CPU, убить контейнер, выключить узел, испортить пакетную сеть) как Kubernetes-ресурсы и запускать эксперименты по расписанию или по запросу. Например, Chaos Mesh (проект CNCF) предоставляет CRD **ChaosExperiment**, через который можно “положить” часть подов или внести задержку в сетевой трафик и затем проверить, выдержит ли сервис. Такая практика помогает выявить скрытые зависимости и убедиться, что системы действительно соответствуют заявленной отказоустойчивости. Лучшие практики рекомендуют интегрировать хаос-тесты в цикл разработки: от прогона отдельных сценариев в staging до целых *Chaos Days* в продакшене, когда отключается, скажем, один из кластеров, и команда отрабатывает DR-процедуры (как это делает, к примеру, Netflix с легендарным Chaos Monkey).

**Балансировка и деградация.** Частью устойчивости является умение системы **деградировать** вместо полного отказа. В 2023 многие сервисы проектируются с *graceful degradation*: при проблемах с дополнительными компонентами (рекомендательные модули, аналитика) основной функционал продолжает работать, пусть и с ограничениями. SRE практики включают настройку timeouts на внешние вызовы, чтобы зависшие компоненты не стопорили всю цепочку, и возврат фолбэк-ответов или кешированных данных, если свежие недоступны. Кроме того, используется **rate limiting** – ограничение нагрузки, чтобы при всплесках трафика сервис деградировал контролируемо (отдавая 429 или «заглушку») вместо краха от перегрузки.

В целом, **отказоустойчивость** в 2023–2024 – это сочетание правильной архитектуры (мультирегион, кластеры), готовности к сбоям (резервы, хаос-тесты) и встроенных механизмов самовосстановления. Крупные сбои облачных провайдеров в последние годы (например, глобальная авария 19 июля 2024 ([Lessons from the Global IT Outage of July 19, 2024](https://www.cyberdefensemagazine.com/lessons-from-the-global-it-outage-of-july-19-2024/#:~:text=2024%20www,to%20distribute%20their%20workloads))) подтолкнули организации пересмотреть стратегии DR: у кого была продуманная *multi-cloud* или хотя бы *multi-region* стратегия – пережили инцидент с минимальным простоем, остальные понесли потери. Так что у бизнесов возросло понимание: **катастрофы случаются**, и к ним надо готовиться технически и организационно.

### Аварийное восстановление (Disaster Recovery, DR)

Если отказоустойчивость – про работу при частичных сбоях, то **Disaster Recovery** – про восстановление после крупных аварий. Лучшая практика – иметь формальный **DR-план** и регулярные тренировки его выполнения. К 2024 всё больше компаний проводят *DR-тесты* не реже раза в год, имитируя полную потерю основного датацентра или компрометацию ключевых систем.

**Резервное копирование.** Классический принцип 3-2-1 (3 копии, 2 типа хранения, 1 – вне площадки) актуален и для облачной эры. Несмотря на надёжность облаков, сбои и человеческие ошибки могут приводить к потере данных. Поэтому распространена практика регулярных **снапшотов баз данных и хранилищ** с сохранением их в отдельном регионе или даже скачивание на свой носитель. Появились облачные решения “Backup as a Service”, однако open-source тоже развиваются: для Kubernetes стандартом стало использовать **Velero** – инструмент для бэкапа/восстановления кластеров (снапшоты persistent volume + экспорт ресурсов кластера). Он позволяет подготовиться к полному восстановлению всего кластера или миграции на новый. Для баз данных популярны утилиты логического бэкапа (mysqldump, pg_dump) или потоковой репликации на удалённый узел, а также **Percona XtraBackup** для горячих бэкапов MySQL/InnoDB. В 2023 наблюдался тренд интеграции средств резервного копирования в общий CI/CD: например, после деплоя критичного обновления база автоматически сохраняется, чтобы иметь точку отката.

**Планы продолжения бизнеса.** Помимо техники, SRE- и инфраструктурные команды формализуют **DR playbooks** – инструкции, кто что делает при полном отключении сервиса. Это включает порядок восстановления из резервов, переключение DNS или IP на резервные сайты, уведомление пользователей. Важна *приоритизация сервисов*: определяются RTO/RPO (допустимое время простоя и потери данных) для каждого компонента, чтобы сосредоточиться на критичных. В 2023 многие компании встроили такие планы в свои процессы и проводили *game days* – учения, воспроизводящие большие сбои, для выявления слабых мест плана.

**Технологии репликации данных.** Для сокращения времени восстановления (RTO) применяются технологии синхронной репликации и **тени среды**. Например, поддержание актуальной копии ключевой базы данных на вторичной площадке, либо использование много-региональных распределённых баз данных (как Spanner, CockroachDB) – тогда при падении региона другой продолжит обслуживать запросы без необходимости восстановления. Облачные провайдеры предлагают управляемые multi-region базы (Aurora Global Database, Cosmos DB и др.), что упрощает достижение DR-целей, хотя и стоит дороже.

**Multi-cloud как стратегия DR.** Отдельно стоит упомянуть **мультиоблачный подход**: некоторые организации резервируют инфраструктуру не только в рамках одного провайдера, но и на другом, чтобы обезопаситься от широкомасштабной аварии или длительного сбоя у одного вендора. Например, поддерживают меньшую копию системы в GCP на случай падения основного AWS, или хранят критичные бэкапы в чужом облаке. Multi-cloud DR сложно реализовать (различия сервисов, необходимости дублировать данные), но 2023 показал рост интереса к нему в чувствительных отраслях. Особенно это стимулируется регуляторами (финансовые организации в ЕС, например, требуют “outsourcing resilience” – устойчивости даже при недоступности поставщика облака).

**Культурные изменения.** SRE практики привносят идею *беспощадной автоматизации* в DR: всё, что может быть автоматизировано – скрипты развёртывания нового окружения, проверки целостности бэкапов, создание временной инфраструктуры для тестового восстановления – должно выполняться машинами, а не людьми в реальном инциденте. В идеале, потерю целого кластера должен компенсировать запуск инфраструктурного кода (Terraform/Ansible) на новой площадке плюс восстановление данных из бэкапов, по нажатию пары кнопок. Многие достигли такого уровня автоматизации к 2024, особенно благодаря облачным API и IaC: *DR-infra-as-code* становится отличительной чертой продвинутых команд.

### Платформенная инженерия и Developer Experience

В 2022–2023 зародилось направление **Platform Engineering** – выделение отдельной команды и набора практик для создания внутренних платформ разработки. К 2024 эта концепция оформилась и набрала популярность, в больших организациях появляясь наряду с DevOps и SRE. Смысл платформенной инженерии – предоставить разработчикам *самообслуживаемую платформу* (“Internal Developer Platform”), скрывающую сложность инфраструктуры и ускоряющую выпуск функциональности.

**Что делает платформа?** Она объединяет CI/CD, облачные ресурсы, базовые сервисы (базы данных, мониторинг, секреты) и предоставляет их через удобные интерфейсы. Например, вместо того чтобы каждый разработчик сам писал helm-чарты и конфигурировал пайплайны, платформа предлагает шаблоны: нажатием кнопки или командой CLI можно развернуть типовой микросервис, подключенный к логированию и метрикам, со всеми лучшими практиками по умолчанию. Популярный open-source проект **Backstage** (от Spotify, теперь CNCF) стал своего рода “витриной” платформы – портал, где разработчики видят каталог сервисов, документацию, кнопки “создать новый сервис” или “зарелизить в прод”. Backstage интегрируется со множеством инструментов (CI-системы, Argo CD, Kubernetes, облака), позволяя платформенной команде собрать единый интерфейс для всего DevOps-стека.

**Изменения 2023–2024:** платформенные команды стали добавляться в организационные структуры многих компаний. Они используют подход “Product Mindset” – относятся к внутренней платформе как к продукту для разработчиков, собирают обратную связь, улучшают UX. В техническом плане Platform Engineering опирается на всё перечисленное выше: IaC, GitOps, Kubernetes. Очень часто ядром платформы является **Kubernetes с операторами** – на нём крутятся инструменты CI/CD, базы данных как сервис (через операторы типа Crunchy for Postgres), шины событий, а команда платформы создает *абстракции* поверх Kubernetes. Например, вместо того, чтобы заставлять разработчика писать Deployment и Service, ему дают простой интерфейс или декларацию “Application”, из которой платформа сама генерирует нужные Kubernetes-манифесты и GitOps-репозиторий. Сервicemesh, мониторинг, ingress – всё настраивается и поддерживается платформой централизованно.

**DevX и золотые пути.** Родственным понятием стало **Developer Experience (DevX)** – удовлетворённость и продуктивность разработчиков. Платформенная инженерия стремится улучшить DevX, предлагая *“Golden Paths”* – лучшие пути решения типичных задач. Например, золотой путь для создания REST API-сервиса: шаблон репозитория + CI + инструкция как кодить с observability hooks. В 2023 появились даже должности Developer Experience Engineer. Это следствие понимания: скорость разработки (а значит, и time-to-market) сильно зависит от удобства внутренних инструментов.

**Инновации enterprise.** Хотя Platform Engineering чаще строится на open-source, некоторые enterprise-решения предлагают готовые платформы. Например, VMware Tanzu и Red Hat OpenShift позиционируются не просто как Kubernetes, а как платформа для приложений (с дополнительными сервисами, каталожными возможностями). Новые продукты, вроде Humanitec, стремятся автоматически собирать окружения под каждое изменение (Ephemeral Environments), упрощая жизнь разработчикам. Тем не менее, лидирует подход “сделай сам на основе open-source” – он гибче и экономичнее.

Важно, что **Platform Engineering не заменяет DevOps/SRE**, а развивается вместе. DevOps-принципы (автоматизация, коллаборация) используются при создании платформы, а SRE-фокус на надёжности гарантирует, что платформа работает стабильно. Сама платформа требует поддержки – мониторинга, обновлений, учёта SLO. Можно сказать, что к 2024 **в крупных организациях формируется связка**: Platform Team обеспечивает self-service и стандарты, Product Teams (разработчики) фокусируются на коде продукта, а SRE/Infra Teams контролируют кросс-функциональные вопросы надёжности, производительности и оптимизации инфраструктуры. Все вместе они реализуют общие цели DevOps – быстро и безопасно доставлять ценность пользователям.

### Практики SRE: SLO, ошибки и инциденты

Site Reliability Engineering, зародившаяся в Google, за последние годы распространилась широко. В 2023–2024 многие компании среднего размера также внедряют элементы SRE. Ключевые практики SRE, которые стали стандартом:

- **SLO/SLI и Error Budgets.** Определение *целей уровня обслуживания* (Service Level Objectives) для ключевых метрик (доступность, время отклика и пр.) – теперь обычное дело не только у техногигантов. Команды договариваются о целевых значениях (например, 99.9% аптайма в месяц) и считают *бюджет ошибок* – сколько неудовлетворенных запросов или минут простоя приемлемо. Этот механизм связывает бизнес и техников: пока бюджет ошибок не исчерпан, можно выпускать новые фичи, а если надёжность просела – фокус смещается на стабилизацию. Вокруг SLO возникли инструменты: **Nobl9**, **Splunk SLO** (enterprise) или open-source генераторы вроде **Sloth**, которые из SLO YAML определений делают Prometheus-алерты. В целом, SLO стали метрикой успеха SRE-команд; отчёты о соблюдении SLO за квартал – норма для зрелых команд.

- **Управление инцидентами.** SRE поощряет **blameless post-mortems** – разбор инцидентов без поиска виноватых, с фокусом на улучшение систем и процессов. За 2023 многие организации внедрили культуры постмортемов: после каждого серьёзного сбоя собирается отчёт с таймлайном, корневыми причинами (RCAs) и action items. Согласно исследованию Catchpoint SRE 2023, 52% компаний признают, что им ещё нужно улучшать процесс разбора крупных инцидентов ([Navigating the SRE Landscape for 2024: A Comprehensive Exploration of Decentralized Practices | APMdigest](https://www.apmdigest.com/navigating-sre-landscape-2024-comprehensive-exploration-decentralized-practices#:~:text=Learning%20from%20Incidents%20)), то есть эта практика в фокусе внимания. Также ценится **Learning from Incidents (LFI)** – обмен уроками между командами, создание базы знаний о прошлых сбоях. Некоторые компании пошли дальше и завели регулярные встречи или рассылки “Incident Review” для всех инженерных команд, где обсуждаются не только свои, но и чужие инциденты. Это повышает общую надёжность за счёт организационного обучения.

- **Автоматизация и устранение рутины.** SRE-инженеры стремятся минимизировать ручной повторяющийся труд (*toil*). В 2023 расширилось применение **авто-ремедиации**: скрипты или автоматические действия при известных проблемах. Пример – при срабатывании аларма “дисковое пространство < 10%” сразу запускается скрипт очистки временных файлов или увеличения диска в облаке. Инструменты как **StackStorm**, **RunDeck** позволяют связывать алерты с действиями. Также растёт популярность *ChatOps* – управление системами через команды в чатах (Slack/Teams), где бот может перезапустить сервис или собрать логи по запросу. Всё это ускоряет реакцию и снижает человеческий фактор.

- **Структура команд.** Интересно, что SRE-функция **эволюционирует организационно**. Согласно опросам, около половины компаний организуют команды по продуктам/сервисам, а другая значительная часть – по платформам или компетенциям ([Navigating the SRE Landscape for 2024: A Comprehensive Exploration of Decentralized Practices | APMdigest](https://www.apmdigest.com/navigating-sre-landscape-2024-comprehensive-exploration-decentralized-practices#:~:text=Structural%20Evolution)). То есть где-то SRE-инженеры встраиваются в продуктовые команды, а где-то существует центральная SRE-группа. В крупных компаниях (>1000 сотрудников) прослеживается тренд комбинации: есть и продуктовые SRE (сидят рядом с девелоперами сервисов), и платформенные SRE (отвечают за общие компоненты – CI/CD, кластер, базу данных). Эта эволюция продиктована поиском баланса между масштабируемостью (централизованные платформенные SRE могут охватить больше систем стандартными средствами) и экспертизой (продуктовые SRE глубоко знают свой сервис).

- **Баланс надежности и скорости.** В 2023, учитывая экономические ограничения, SRE-командам часто приходилось делать больше с меньшими ресурсами. В опросе Catchpoint ~44% компаний назвали **оптимизацию затрат** и нехватку людей одной из главных проблем ([Navigating the SRE Landscape for 2024: A Comprehensive Exploration of Decentralized Practices | APMdigest](https://www.apmdigest.com/navigating-sre-landscape-2024-comprehensive-exploration-decentralized-practices#:~:text=As%20the%20SRE%20landscape%20continues,DNS)). Поэтому SRE все чаще вовлекаются в **оптимизацию производительности и стоимости** (например, тюнинг облачных ресурсов, чтобы не переплачивать, но и не получить деградаций). Появилась связка SRE с **FinOps** – практиками управления затратами в облаке, поскольку надежность и эффективность инфраструктуры идут рука об руку.

В итоге, **SRE практики** к 2024 стали частью мейнстрим-DevOps: даже если в компании нет должности "SRE", многие следуют принципам SRE – измеряют *error budget*, автоматизируют ручные задачи, улучшают наблюдаемость и готовность к инцидентам. Организации, следующие этим практикам, как правило, добиваются более устойчивых и предсказуемых сервисов, способных быстро восстанавливаться из сбоев и меняться без ущерба качеству.

## Инструменты: лидеры и новинки

Разнообразие инструментов для DevOps/SRE за последние годы продолжало расти. Ниже рассмотрены наиболее используемые и появившиеся в 2023–2024 инструменты по категориям – с их назначением, плюсами и минусами, а также кейсами применения. Основное внимание уделено open-source проектам, однако для полноты картины упоминаются и некоторые значимые проприетарные решения.

### Инструменты CI/CD

| Инструмент CI/CD               | Описание и особенности                                                                          | Плюсы                                              | Минусы                                             |
|-------------------------------|-------------------------------------------------------------------------------------------------|----------------------------------------------------|----------------------------------------------------|
| **Jenkins**                   | Старейший и самый распространённый сервер CI/CD. Расширяемый через ~1800 плагинов.               | *Очень гибкий*: можно настроить любой процесс;<br>*Большое сообщество* и наработанные практики. | *Требователен к поддержке*: нуждается в администрировании, обновлениях;<br>*Монолитность*: слабая встроенная масштабируемость, каждый job запускается на агенте, что требует управлять флотом агентов вручную. |
| **GitLab CI/CD**              | Встроенная CI/CD в платформу GitLab. Pipeline описываются в `.gitlab-ci.yml` внутри репозитория. | *Интеграция с SCM*: один интерфейс для кода и конвейера;<br>*Авто DevOps*: шаблоны пайплайнов, Container Registry, трекинг релизов из коробки. | *Требует GitLab*: используется преимущественно в связке с GitLab SCM;<br>*Ограниченная масштабируемость* в open-source варианте (enterprise добавляет более тонкое управление). |
| **GitHub Actions**            | CI/CD-as-code в GitHub. Workflows в формате YAML, огромный каталог готовых Actions (шагов).      | *Простота старта*: легко активировать в репозитории;<br>*Marketplace*: тысячи готовых экшенов (для деплоя, тестов и пр.);<br>*Хорошо подходит для open-source проектов*. | *Зависимость от GitHub*: работает только в GitHub; <br>*Ограничения без оплаты*: в бесплатной версии ограничены минуты на сборку (для частных репо). |
| **Argo Workflows**            | Open-source движок CI на Kubernetes (CNCF). Описывает workflow как CRD (Custom Resource) в k8s: набор шагов, которые могут быть контейнерами. | *Cloud-native*: отлично интегрируется в k8s-кластер, может масштабироваться на подах;<br>*Поддерживает DAG и параллелизм*: удобно для data processing, ML и других параллельных задач. | *Сложнее настройка*: требует знаний Kubernetes и манифестов;<br>*Нет своего SCM*: обычно триггеры через внешние ивенты (например, Argo Events) или интеграция с GitOps. |
| **Tekton Pipelines**          | Компонентная CI/CD платформа (CNCF). Представляет собой набор CRD для создания задач и конвейеров в k8s. | *Гибкость и стандарты*: Tekton является основой для CI/CD в OpenShift, Jenkins X и др.;<br>*Контейнеризация*: каждый шаг в контейнере, легко использовать в разных средах. | *Низкоуровневый*: требуются дополнительные надстройки/UI (те же Jenkins X) для удобства;<br>*Меньше готовых шаблонов*: по сравнению с Jenkins или GitHub Actions. |
| **Spinnaker**                 | Многооблачная платформа Continuous Delivery, open-source (Netflix). Специализируется на deployment (развертывание артефактов). | *Мощный deployment orchestration*: поддерживает канареечные релизы, мониторинг, много целевых платформ (Kubernetes, AWS, GCE и др.);<br>*Подходит для сложных сценариев*: где нужен контроль над стадиями развертывания. | *Сложность*: тяжелый в развёртывании, множество компонентов (Microservices architecture);<br>*Ограниченная CI часть*: не занимается сборкой/тестами, часто используется совместно с Jenkins или GitHub Actions. |
| **GitOps Operators (Argo CD/Flux)** | Хотя это не традиционные “CI/CD” в классическом понимании, они автоматизируют CD: тянущие операторы, доставляющие конфигурацию из Git. | *Надёжность деплоя*: см. раздел GitOps выше – отсутствие ручных шагов, автосинхронизация;<br>*Отлично для Kubernetes*: стандартный способ CD в k8s. | *Ограничены декларативным миром*: плохо подходят для пошаговых сборочных процессов или нетривиальной логики до деплоя (например, миграции БД – их нужно обрабатывать отдельно). |

**Тенденции:** Jenkins постепенно теряет позиции, хотя ещё широко используется в корпоративных средах. В новых проектах чаще выбирают *git-native* подходы (GitLab/GitHub) или Kubernetes-native (Tekton/Argo) для лучшей совместимости с cloud-native стеком. Интересной новинкой 2023 стал **Harness CI** (enterprise SaaS CI/CD с AI-помощниками) и **CircleCI Server 3.0**, но open-source сообщество в основном сконцентрировано вокруг перечисленных решений. Также, во многих компаниях практикуется смешанный подход: например, GitHub Actions для запуска unit-тестов и сборки контейнера, а затем Argo CD для развертывания этого контейнера на кластер. Это сочетает простоту CI в GitHub с надёжностью CD в Kubernetes.

### Инструменты GitOps

| Инструмент GitOps         | Описание и применение                                                      | Плюсы                                                        | Минусы                                                       |
|---------------------------|---------------------------------------------------------------------------|--------------------------------------------------------------|--------------------------------------------------------------|
| **Argo CD**               | GitOps-оператор (CNCF Graduated) для Kubernetes. Мониторит гит-репозиторий с манифестами и применяет их в кластер. Имеет веб UI. | *Прост в использовании*: развернул оператор – подключил репо, дальше автоматизация;<br>*UI и визуализация*: удобно наблюдать статус синхронизации, diff’ы, историю;<br>*Большая адопция*: много примеров, интеграция с Argo Rollouts для progressive delivery. | *Заточен на Kubernetes*: для других целей (например, управление облачными ресурсами) из коробки не годится;<br>*Ресурсоёмкость*: при тысячах приложений в одном ArgoCD могут быть сложности с масштабированием (решается sharding’ом по нескольку экземпляров). |
| **Flux CD**               | GitOps-оператор (CNCF) второй версии. Состоит из набора контроллеров (source-controller, kustomize-controller и др.), обеспечивает доставку из Git в кластер. | *Модульность*: можно включать только нужные компоненты (например, синхронизация Helm charts);<br>*Лёгкая встраиваемость*: как headless service без UI, хорошо интегрируется в другие платформы;<br>*Расширяемость*: поддерживает расширения (Flux plug-ins) – например, Terraform-controller, Flagger для canary. | *Отсутствие встроенного UI*: требуются доп. инструменты (Weave GitOps UI или интеграция с ArgoCD через Flamingo);<br>*Более крутая кривая обучения*: концепции GitRepository/Flux Kustomization требуют понимания. |
| **Helm + Flux/Argo**      | Не отдельный инструмент, а паттерн: использование Helm-чартов в GitOps. ArgoCD и Flux умеют работать с Helm (отслеживать Chart в Git или в репозитории). | *Комбинирует преимущества*: Helm – для упаковки и параметризации, GitOps – для автоматического деплоя версий;<br>*Повторное использование*: общие чарты могут использоваться во многих приложениях через один GitOps оператор. | *Сложность отладки*: если что-то пошло не так, надо разбираться и в Helm-шаблонах, и в логике оператора;<br>*Дублирование версионирования*: версии чарта vs состояния в Git могут запутывать (но практики решают фиксировать чётко версии). |
| **Terraform Cloud/Enterprise (в режиме VCS-встроенности)** | Коммерческое SaaS/самостоятельное решение от HashiCorp, которое автоматически применяет Terraform-планы при изменениях в связанных Git-репозиториях. | *Удобство для Terraform-пользователей*: не надо писать свой бот, всё происходит по webhook’ам;<br>*Дополнительные функции*: управление переменными, разделение прав, политика Sentinel (policy as code). | *Проприетарность*: закрытый код и возможные издержки стоимости;<br>*Ограничено IaC*: не управляет приложениями, Kubernetes-манифестами и т.п., только тем, что описано Terraform. |
| **Flux Terraform Controller** | Модуль FluxCD, позволяющий Flux-оператору выполнять Terraform-модули как часть GitOps потока.    | *Единый контроль*: Kubernetes-центричный подход ко всей инфраструктуре, не выходя за рамки GitOps;<br>*Open-source эксперимент*: интересно для исследователей multi-IaC. | *Новая технология*: пока менее популярна, возможно, не столь зрелая для продакшна крупной инфраструктуры;<br>*Сложность*: отладки Terraform при запуске из Kubernetes. |

В целом, на 2024 год **Argo CD и Flux** делят лидерство в GitOps. Argo чуть более популярен в standalone-использовании, Flux – в составе других решений. Например, *OpenShift GitOps* основан на Argo CD, а *Rancher Fleet* – концептуально ближе к Flux (хотя это отдельный проект). Оба инструмента активно развиваются сообществом. Интересный момент – **GitOps для многокластерных и edge-сред**: и Argo, и Flux могут управлять не одним, а сразу десятками кластеров Kubernetes (*fully decentralized GitOps*). Это стало важным в 2023, когда крупные пользователи начали применять GitOps для **управления тысячами edge-устройств** (см. пример JYSK с 3000+ k3s-кластеров, управляемых через Flux ([Unleashing the Power of k3s for Edge Computing: Deploying 3000+ in-store Kubernetes Clusters — Part 1 | by Ryan Gough | JYSK Tech](https://jysk.tech/unleashing-the-power-of-k3s-for-edge-computing-deploying-3000-in-store-kubernetes-clusters-part-77ecc5378d31#:~:text=Modern%20application%20deployment%2C%20particularly%20at,configuration%20and%20version%20we%20desire))).

### Инструменты IaC и конфигурации

| Инструмент IaC                 | Язык/подход            | Плюсы                                                         | Минусы                                                    | Основные кейсы                        |
|--------------------------------|------------------------|---------------------------------------------------------------|-----------------------------------------------------------|---------------------------------------|
| **Terraform** (HashiCorp)      | Декларативный DSL (HCL); push-модель через API провайдеров. | *Универсальность*: работает с множеством платформ (облака, VM, БД, DNS и пр.) ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=1.%20Multi,Terraform%20takes%20over%20key%20networking));<br>*Сообщество и модули*: готовые модули во многих репозиториях (Terraform Registry);<br>*Обширный функционал*: зависимости, локальные вычисления, планирование изменений. | *Состояние (state)*: нужно хранить и синхронизировать, возможны конфликты;<br>*Нет встроенного drift detection*: изменения вне Terraform остаются незамеченными до запуска;<br>*Лицензия*: новые версии под BSL (см. выше). | Автоматизация создания инфраструктуры в облаке (сетей, VM, сервисов);<br>Multi-cloud конфигурации;<br>Управление ресурсами, не покрытыми Kubernetes. |
| **Pulumi**                     | Общие языки (TS/JS, Python, Go, .NET, Java). Императивный код -> декларативное применение через провайдеры. | *Код как код*: использование условий, циклов, функций, модулей – повышает гибкость;<br>*Можно объединять логику приложения и инфраструктуры*: например, деплой функций + код, генерирующий конфигурацию (в одном проекте). | *Сложность для инфраструктурщиков*: нужно знать язык и экосистему (npm/pip modules);<br>*State similarly*: также использует state backend, аналогичен Terraform здесь;<br>*Меньше провайдеров*: покрытие близкое, но Terraform традиционно быстрее получает новые провайдеры. | Сложные сценарии, где HCL/Terraform плохо выразим (генерация множества ресурсов по алгоритму);<br>Интеграция IaC в приложения (например, деплой инфраструктуры прямо из кода приложения при запуске). |
| **Ansible**                    | YAML + Jinja (декларативно-императивный). Push по SSH/WinRM или через агенты. | *Простота начала*: читаемый YAML для задач;<br>*Масштабируемость через inventory*: управляет сотнями узлов параллельно;<br>*Модули*: богатый набор модулей (от системных команд до облачных API). | *Идемпотентность за счёт разработчика*: нужно писать роли с учётом повторного запуска;<br>*Скорость*: при большом числе мелких задач может быть медленным (SSH overhead);<br>*Не отслеживает состояние*: если вне Ansible что-то изменили, он не «знает» об этом. | Настройка серверов (конфиги, пользователи, развертывание ПО) особенно на VM и bare-metal;<br>Оркестрация последовательных операций (развернуть БД, потом приложение);<br>Ад-хок задачи на группах серверов. |
| **Helm** (Kubernetes)         | YAML + Go-шаблоны (chart). Пакетный менеджер для Kubernetes-манифестов. | *Стандартизация деплоя приложений*: тысячи готовых Helm-чартов (Helm Hub/ArtifactHub);<br>*Параметризация*: values.yaml позволяет настраивать деплой без изменения шаблонов;<br>*Release management*: Helm хранит историю релизов, что упрощает откаты. | *Шаблонизация сложна в отладке*: легко допустить ошибку в шаблоне; YAML внутри YAML;<br>*Ограниченность Go-template*: нет полноценных циклов (есть range) и условий (только if), что ведёт к хитрым трюкам;<br>*Внешнее управление состоянием*: до Helm 3 требовался Tiller (устарел). | Развёртывание самих инфраструктурных приложений (NGINX ingress, Prometheus) в k8s;<br>Доставка собственных микросервисов в k8s с версионированием конфигов;<br>Упаковка приложений для передачи клиентам (ISV поставляют Helm charts). |
| **Kustomize** (Kubernetes)     | Чисто декларативный YAML-patch подход (builtin в kubectl). | *Без шаблонов*: использует наложение "овералеев" (overlays) YAML, уменьшая дублирование конфигов;<br>*Встроен в kubectl*: не нужны доп. бинарники для базового использования. | *Ограниченная выразительность*: сложные изменения конфигурации неудобно делать патчами;<br>*Менее популярен для приложений*: уступает Helm в экосистеме готовых пакетов. | Создание вариаций K8s-манифестов для разных сред (dev/prod) без дублирования;<br>Совместное использование с GitOps (ArgoCD умеет применять Kustomize). |
| **Crossplane** (Upbound)      | Декларативный (YAML CRDs в Kubernetes). Управление внешними ресурсами через Kubernetes. | *Единый контроль-плэйн*: можно всеми инфраструктурными ресурсами управлять через знакомый K8s API;<br>*Композиции*: Crossplane позволяет платформ. командам создать свои CRD (например, “ProductionDB”) которые внутри создают набор облачных ресурсов – упрощение для пользователей платформы. | *Требует Kubernetes-кластера*: дополнительный слой, усложняющий архитектуру;<br>*Молодая экосистема*: провайдеры закрывают основные облака, но менее проверены временем, чем Terraform;<br>*Отладка*: труднее отслеживать ошибки создания ресурсов, скрытые в событиях Kubernetes. | Сценарии Platform Engineering: самописные сервисы-операторы для выдачи инфраструктуры “как сервис” разработчикам;<br>Гибридное облако: Crossplane-оператор в каждом кластере создаёт ресурсы локально и в облаке, согласуя их состояние. |
| **CloudFormation / ARM / CDM** (облачные DSL) | Декларативные шаблоны (JSON/YAML) для AWS, Azure, GCP соответственно. | *Нативность*: поддерживаются самим облачным провайдером, всегда актуальны под новинки;<br>*Интеграция*: глубоко вплетены в экосистему (например, CloudFormation StackSets, управление через консоль AWS). | *Вертикальная привязка*: не работают вне своего облака;<br>*Шаблоны становятся громоздкими*: особенно CFN JSON – очень большой и многословный. | Используются в основном в рамках данного облака организациями, выбравшими “everything on AWS/Azure” подход; часто генерируются через Terraform/CDK. |

Кроме перечисленных, существуют узкоспециализированные инструменты: **Packer** (HashiCorp) для автоматизации создания образов VM/AMI – важен для immutable инфраструктуры; **SaltStack** – еще одна система конфигурирования (на Python, менее распространена сейчас); **Chef/Puppet** – уже упомянутые, со своими DSL (Ruby-based), которые все реже фигурируют в новых проектах.

**Новинки 2023:** Winglang (уже описан ранее) – пока лишь привлёк интерес, но до production-ready ему далеко. **CDKTF** (Terraform CDK) – попытка HashiCorp объединить лучшее из Terraform и Pulumi, позволив писать Terraform-конфигурации на TypeScript/Python через CDK-обёртку. Проект находится в стадии развития: он позволяет обращаться к провайдерам Terraform внутри кода, а затем компилировать в HCL. Но после изменения лицензии Terraform судьба CDKTF неясна – сообщество может переключиться на OpenTofu + Pulumi.

**Выбор инструмента IaC** в 2024 зачастую комбинирован: Terraform (или его open-source форки) – основной для инфраструктуры, Helm/Kustomize – для Kubernetes-манифестов приложений, Ansible – для задач конфигурации ОС и оркестрации rollout’ов (например, обновление баз данных с выгрузкой-схемой-загрузкой). Такой многослойный подход считается нормой, важно лишь синхронизировать эти инструменты и обеспечить их согласованное применение через общие пайплайны и GitOps.

### Инструменты мониторинга и наблюдаемости

| Инструмент              | Тип данных        | Назначение и особенности                                                                       |
|-------------------------|-------------------|-----------------------------------------------------------------------------------------------|
| **Prometheus**          | Метрики (timeseries) | Система мониторинга (CNCF Graduated). Сбор метрик с помощью pull (scraping) с экспортеров или push gateway. Имеет язык запросов PromQL. Стал стандартом для метрик: *70% компаний используют Prometheus* ([OpenTelemetry Announces General Availability | APMdigest](https://www.apmdigest.com/opentelemetry-announces-general-availability#:~:text=Open%20source%20dominance%20continues%20in,both%20technologies%20for%20the%20second)), огромное количество интеграций (CNCF проекты по умолчанию экспонируют метрики для Prometheus). Масштабируется через федерацию или системы поверх (Thanos, Cortex). |
| **Grafana**             | Визуализация (метрики, логи, трейсы) | Дашбординг и алертинг. Позволяет строить графики по данным из множества источников – Prometheus, Graphite, Elasticsearch, Loki, Tempo и др. De-facto стандарт UI для наблюдаемости. Имеет развёртываемые алерты (с 8-й версии – Alerting в составе Grafana). Open-source, но также есть Grafana Cloud (hosted). |
| **ELK / EFK Stack**     | Логи              | Elasticsearch + Logstash/Fluentd + Kibana – популярный стек для централизованного логирования. **OpenSearch** – форк Elasticsearch от Amazon (open-source) – теперь часто заменяет ElasticSearch в связке (так говорят *EOK* stack). Предоставляет полнотекстовый поиск, дашборды Kibana для логов. Поддерживает схемы индексации, JSON-логирование. Хорош для анализов и сложных поисков по логам, но требует значительных ресурсов на больших объёмах данных. |
| **Loki**                | Логи (метрики-ориентированные) | Новое решение от Grafana Labs для логирования. Хранит логи с индексом по метаданным (лейблам) вместо текста, что делает его более экономичным. Интегрируется с Grafana (сквозной поиск по метрикам и логам). Идеально подходит для Kubernetes-логов, где можно метить потоки (namespace, pod и т.д.). Проще в развёртывании, чем ELK, но менее эффективен для сложных текстовых запросов (т.к. без индексирования текста). |
| **Jaeger**              | Трассировки (tracing) | Open-source система распределённого трейсинга (CNCF). Состоит из агентов, коллектора и хранилища (по умолчанию Cassandra или Elastic, либо встроенный memory). Позволяет собирать и визуализировать трейсы (спаны) запросов через микросервисы. Поддерживает стандарты OpenTracing, а сейчас и OpenTelemetry (через её коллектор). В 2023 является базовым решением для многих, кто внедряет трассировку, если не используется коммерческий APM. |
| **Tempo**               | Трассировки        | Другой open-source трейсинг-бекенд от Grafana. Хранит трейсы очень экономично (без индекса, по концепции “прикрепляем трейсы к метрикам”), масштабируется кластерно. Интегрируется с Grafana UI (поиск трейса по меткам). Выигрывает у Jaeger на очень больших объёмах, т.к. проще масштабировать хранение. |
| **OpenTelemetry**       | Фреймворк телеметрии | SDK и Collector (агент) для метрик, логов, трейсов. *Не хранилище, не UI*, а именно инструмент сбора и экспорта данных. Стал GA в 2023 ([OpenTelemetry Announces General Availability | APMdigest](https://www.apmdigest.com/opentelemetry-announces-general-availability#:~:text=At%20KubeCon%20%2B%20CloudNativeCon%20North,0)). Используется как стандартный способ инструментировать приложения: вместо разных клиентов (Prometheus client, Zipkin client и т.д.) – единый OTel SDK, конфигурируемый на экспорт в нужный бекенд (Prometheus, Jaeger, etc). Collector может делать предварительную обработку: напр. объединять логи, делать семплинг трейсов. Благодаря OpenTelemetry, стали возможны гибридные решения – напр. послать часть данных в свою open-source систему, а часть дублировать в облачный мониторинг. |
| **Alertmanager**        | Алертинг           | Компонент экосистемы Prometheus. Получает алерты от Prometheus (или других систем через webhook) и осуществляет маршрутизацию уведомлений (на e-mail, Slack, PagerDuty и т.д.), поддерживает группировку и подавление (suppress) похожих алертов. Практически всегда разворачивается вместе с Prometheus. |
| **PagerDuty / VictorOps / OpsGenie** | Оповещение (On-call) | Коммерческие инструменты для управления дежурствами и инцидентами. Интегрируются с Alertmanager или напрямую с мониторингом. Предоставляют удобство расписаний дежурств, эскалаций, квитирования оповещений. В open-source полного аналога нет (старый project PagerTree или по сути ручное составление календарей). Многие компании используют хотя бы один из таких сервисов для серьёзных систем. |
| **Zabbix / Nagios**     | Метрики/Алерты (legacy) | Классические инструменты мониторинга (агент + сервер). В облачно-родных системах почти не используются для новых проектов, но всё ещё встречаются в традиционных инфраструктурах (серверы/сеть). Предоставляют сбор метрик, проверку доступности (ping, port), простые дашборды. Open-source, но тяжеловесны в управлении по сравнению с Prometheus-стеком. |

**Enterprise APM & Observability:** Помимо открытых инструментов, широко применяются и SaaS/enterprise решения, особенно в крупных компаниях, ценящих “всё в одном окне”. Среди лидеров: **Datadog** (включает метрики, логи, APM, синтетические тесты – очень популярен в облачных стартапах), **New Relic**, **Dynatrace**, **Splunk Observability (SignalFx)**, **Elastic Cloud**. Эти решения зачастую предоставляют более продвинутый анализ (напр. автоматическое обнаружение аномалий, трассировка без семплирования, оптимизированные мобильные алерты). Но их стоимость высока, и зависимость от вендора. Тренд 2023 – многие ищут баланс: использовать открытый стек (Prom+Grafana) для базовых нужд, а точечно применять SaaS для узких задач (например, Datadog только для APM, где нужна глубокая трассировка, а метрики – в Prometheus).

**Инструменты для конкретных доменов:** Отдельно отмечу, что существуют спецрешения: например, **Cadvisor** и **Node Exporter** – для метрик контейнеров и узлов (встроены в Kubernetes); **cPanel** или **LibreNMS** для мониторинга сетевого оборудования; **Sentry** – для мониторинга ошибок приложений (ошибки, исключения на уровне кода) с удобством для разработчиков. DevOps-инженерам в 2024 важно выстраивать *интегрированную картину*: собирать данные из разных источников в единую систему обзора. Нередко практикуют объединение метрик и логов с помощью систем вроде **Grafana Unified Alerting** или создания своих мостов (например, парсинг логов и отправка ключевых метрик в Prometheus).

### Инструменты для отказоустойчивости, тестирования надёжности и безопасности

Сюда относятся сервисы, облегчающие реализацию тех практик отказоустойчивости и DR, о которых говорилось выше:

- **Service Mesh (Istio, Linkerd, Consul Mesh):** обеспечивают прозрачное внедрение отказоустойчивости и безопасности на уровне сети. **Istio** к 2023 году стал зрелым (вошёл в CNCF), многие организации внедрили его для микросервисных архитектур. Он предоставляет автоматические retries запросов, отсечения (circuit breaking), балансировку между версиями (для канареек) и метрические данные по трафику. **Linkerd** – более лёгкий mesh, фокусируется на простоте, но тоже даёт базовые механизмы надёжности. **Consul Connect** (HashiCorp) – альтернатива с интеграцией в экосистему Consul. Mesh-инструменты стоит упомянуть, т.к. их наличие в стеке часто упрощает реализацию лучших практик (не надо в каждый сервис кодить повторные попытки – mesh сделает это сам согласно политике).

- **Chaos Engineering Tools:**
  - *Open-Source:* **Chaos Mesh** (CNCF проект) – предоставляет CRD типа *PodChaos, NetworkChaos* и т.п., которыми можно управлять хаотизацией. Имеет панель управления Chaos Dashboard для запуска экспериментов. **LitmusChaos** – предлагает готовые сценарии (эксперименты) на разный вкус: от вырубания ноды до повышения нагрузки CPU. Оба позволяют интегрировать хаос-тесты в CI (например, запускать сценарий после деплоя на stage и проверять, что система выдерживает).
  - *Коммерческие:* **Gremlin** – один из первых сервисов Chaos-as-a-Service; **AWS Fault Injection Simulator (FIS)** – сервис AWS для сценариев с отключением инстансов, имитации ошибок в AWS-сервисах, полезен для тестирования AWS-инфраструктур.
  - *Сообщества:* Вокруг chaos engineering сформировалось сообщество, проводятся регулярные **GameDays** (те же Days of Chaos) – 2023 принёс больше открытых шаблонов для их проведения.

- **Load Testing & Performance:**
  - **k6** (Grafana) – современный open-source инструмент нагрузочного тестирования, сценарии на JS. Используется DevOps-инженерами для проверки производительности сервисов, особенно после изменений (чтобы убедиться, что error budget не съестся из-за выросшего latency). k6 интегрируется с Grafana (можно визуализировать результаты), и даже с CI (падать, если перформанс хуже заданного).
  - **JMeter** – старый, но до сих пор применимый для сложных сценариев (протоколы, JDBC, скрипты). Однако в 2023 чаще выбирают k6 или Gatling (на Scala) за более современный подход.
  - **Vegeta, Locust** – тоже известные open-source нагрузочные генераторы (Vegeta – CLI утилита, Locust – на Python с web UI).
  - Эти инструменты помогают *проактивно* выявлять узкие места и настроить авто-масштабирование до того, как придёт реальный трафик.

- **Инструменты Backup/Recovery:**
  - **Velero** – уже упоминался, стандарт K8s backup.
  - **Restic** – универсальная утилита резервного копирования на уровне файлов, используется и самостоятельно, и под капотом у Velero.
  - **BorgBackup (Borg)** – популярный в open-source для дедуплицированных бэкапов.
  - **Cloud-native backups**: все три крупных облака имеют свои средства (AWS Backup, Azure Vault, GCP Backup for GKE etc.), но опенсорсники зачастую комбинируют свои решения для большей портативности.
  - **Database-specific**: Percona XtraBackup (MySQL InnoDB горячие бэкапы), WAL-G (архивация WAL для Postgres), Minio для S3-совместимого хранения бэкапов – весь этот инструментарий составляет основу DR-стратегий.

- **Secrets Management:** обеспечение секрета – часть надёжной инфраструктуры (предотвращение эксплойтов). В open-source лидирует **HashiCorp Vault** – хранилище секретов с динамическими секретами, ротацией, K/V хранилищем. Vault стал стандартом фактически. Из облачных – AWS Secrets Manager, Azure Key Vault, Google Secrets. В Kubernetes своё движение: Secrets в etcd – не идеально, поэтому используют внешние провайдеры (Vault + CSI драйвер, External Secrets Operator). В 2023–24 усилилось внимание к Zero-Trust, а хранение секретов – его элемент.

- **Конфигурация и Feature Flags:** кроме упомянутых feature flag систем (LaunchDarkly, Unleash), есть **Consul** (KV-хранилище конфигурации и сервис-дискавери). Он вписывается как компонент надежности: позволяет сервисам находить друг друга и переключаться между датацентрами, хранит параметры, которые можно менять без перезагрузки приложений (toggle фич, thresholds). Конкуренты: **Etcd** (внутри K8s и не только), **Zookeeper** (старое поколение, еще жив, например, в Kafka для координат).

### Платформы и оркестрация

*(Эта категория подробнее раскрывается в следующем разделе “Платформы”, здесь кратко перечислим как инструменты.)*

- **Docker / Containerd / CRI-O:** контейнерные движки. Docker – по-прежнему используется разработчиками для локальной работы, но в продакшене его роль часто выполняет Containerd (в Kubernetes по умолчанию) или CRI-O (в OpenShift). Контейнеризация – базис cloud-native. В 2023 вышел Docker 24.x, containerd 1.7 – улучшения безопасности, поддержки cgroup v2 и пр. Остаются важными элементами инфраструктуры.

- **Kubernetes**: главная платформа оркестрации контейнеров (CNCF Graduated). Инструменты вокруг: kubeadm, kOps, KubeSpray для установки, *kubectl* как основной CLI. Kubernetes Operators (написанные на фреймворках Operator SDK, Kubebuilder) – по сути инструменты автоматизации управления сервисами (типа базы данных, кэши) внутри K8s, что позволяет declarative управлять даже сложными stateful компонентами.

- **Офлайн оркестрация / Alt-Stack:** HashiCorp Nomad – более простой планировщик, единственный серьёзный конкурент K8s в open-source. Лёгок в использовании, но не обладает таким обширным сообществом. Используется, например, для оркестрации в **multi-datacenter** средах, где K8s избыточен.

- **Серверлесс-платформы:** Open-source варианты – **OpenFaaS**, **Knative**. Knative (графика eventing + serving поверх K8s) в 2023 достиг высокой стабильности, многие PaaS (как Google Cloud Run for Anthos) на нём основаны. OpenFaaS – простой и легковесный FaaS, интегрируется с Kubernetes. Эти инструменты позволяют разрабатывать функции, которые автоматически масштабируются до нуля и потребляют ресурсы только по событию.

- **Edge orchestration:** **K3s** – легковесный дистрибутив Kubernetes (от Rancher/SUSE) для edge, IoT, dev. **KubeEdge** – надстройка над K8s, позволяющая управлять ресурсами на разрозненных устройствах (подключаемых с перебоями) через центр. В 2023 KubeEdge показал себя на практике в телеком-проектах, создавая мост между центром и краем с помощью CloudHub и EdgeHub компонентов. **MicroK8s** – snap-пакет Kubernetes от Canonical, удобен для single-node сценариев (CI, edge). **Docker Swarm** – фактически утратил позиции; **Apache Mesos** – почти не встречается вне очень специфических окружений.

- **VPN и сети:** хотя и не строго платформа, но: **WireGuard, Tailscale** – инструменты, облегчающие создание сетей между облаками и on-prem (актуально для гибридной инфраструктуры). Они позволяют сделать безопасные mesh-VPN, объединяя разные среды.

Современная инфраструктура – комбинация вышеперечисленных инструментов. Best practice – выбирать каждый компонент, учитывая требования и масштаб. Главное – обеспечить их совместную работу: например, Kubernetes + Vault для секретов, ArgoCD для GitOps, Prometheus+Grafana для мониторинга – типичная связка open-source платформы.

## Платформы (облако, контейнеры, гибридные и edge-среды)

В данном разделе обобщаются **инфраструктурные платформы** – то есть крупномасштабные решения, на базе которых строятся современные системы. Речь идёт об облачных провайдерах, контейнерных платформах, edge-решениях и гибридных стратегиях. 2023–2024 годы принесли эволюцию этих платформ, усилив акцент на гибкости и универсальности.

### Облачные платформы: AWS, Azure, GCP и др.

**Общественный ландшафт облаков** почти не изменился структурно: Amazon Web Services (AWS) – крупнейший игрок, Microsoft Azure – на втором месте с быстром ростом, Google Cloud Platform (GCP) – третий. Эти три гиперскейлера доминируют, предлагая сотни managed-сервисов. В индустрии сложился подход **multi-cloud архитектур**, но на практике полностью равноправное использование нескольких облаков – редкость. Чаще компания выбирает одного *основного* провайдера, а второй – для специфичных задач или как DR площадку. Тем не менее, *облачные провайдеры* сами облегчают клиентам гибридность: в 2023 они активно продвигали решения для работы на чужой инфраструктуре:

- **AWS Outposts / Local Zones:** аппаратные стойки AWS, устанавливаемые в датацентр клиента, обеспечивают запуск AWS-сервисов локально. 2024: расширение линеек Outposts (разные форм-факторы, от стоек до устройств) – популярно у отраслей с низкими задержками (телеком, производство).
- **Azure Arc:** платформа, позволяющая подключить свои сервера, VM и Kubernetes-кластеры к Azure и управлять ими как ресурсами Azure. Также Azure Stack (серия решений для on-prem облака) продолжает развиваться. Azure делает упор на гибридность, интеграция с Windows Server и VMware vSphere.
- **Google Anthos:** решение для управления Kubernetes-кластерами в разных облаках и on-prem, плюс связка сервисов (Anthos Service Mesh, Anthos Config Management) – предоставляет единый слой управления. В 2023 Anthos получил больше клиентов, особенно среди тех, кто исторически не может всё вынести в публичное облако.

**Открытые альтернативы:** для создания своих частных облаков по-прежнему применяется **OpenStack** – открытая платформа для IaaS. Она довольно сложна, но в 2023 вышел релиз Antelope, продолжающий развитие. OpenStack используется телекомами, хостинг-провайдерами и крупными предприятиями для построения AWS-подобной функциональности (VM, сети, образы, хранение) в своих ЦОД. Также **CloudStack** и **VMware vCloud/vSphere** – в enterprise-секторе. Однако, многие организации сместили фокус с прямого воспроизведения облака (IaaS) к **контейнерным платформам** (PaaS).

**Менеджмент и FinOps:** Упоминалось выше – **FinOps** (Financial Operations) стал важной практикой: в облаке легко масштабироваться, но есть риск “шока от счёта”. В 2023 почти все крупные клиенты завели процессы оптимизации затрат: мониторинг неиспользуемых ресурсов, резервация инстансов, автоматическое выключение стендов по расписанию. Появились инструменты как **CloudHealth, Apptio Cloudability** (опять же enterprise) и open-source инициативы (например, Terraformer для выписки актуальных цен). SRE/DevOps стали взаимодействовать с финансовыми отделами, что ранее было необычно, – чтобы балансировать стоимость и производительность.

**Новые сервисы облаков:** Каждый год гиперскейлеры анонсируют десятки новых сервисов. В 2023–2024 тренды:
- **Безсерверные базы данных и процессы:** после Lambda (AWS) аналогичные функции есть у Azure и GCP, а AWS пошёл дальше – Aurora Serverless v2 (Автоштабируемая база), Glue Elastic Views, Google Cloud Spanner evolutions – всё, что освобождает от управления серверами, набирает популярность.
- **Специализированное железо:** AWS Graviton (ARM-процессоры) – всё больше сервисов перевели на ARM для эффективности (EC2, Lambda, Fargate). Azure и GCP тоже предлагают ARM варианты. Значит DevOps должны учитывать многоплатформенные контейнеры (multi-arch образы) как best practice.
- **Data и ML платформы:** рост сервисов для больших данных, MLops (AWS SageMaker features, GCP Vertex AI, Azure ML). DevOps-инженеры тех команд осваивают эти сервисы, интегрируя их в pipeline, но это отдельная большая тема.
- **Облачные сервисы Kubernetes:** EKS, AKS, GKE стали практически стандартным способом поднять Kubernetes – мало кто теперь вручную ставит кластеры для продакшна, когда есть managed-опции. 2023: AWS добавил EKS-Anyhwere (для on-prem), GKE улучшил multicluster, Azure – добавил возможности конфиденциальных контейнеров (TEE for AKS).
- **Edge-облака:** Cloudflare, Akamai, Fastly – CDN-провайдеры – превратились в платформы бессерверных edge-функций (Cloudflare Workers, Akamai EdgeWorkers). Они позволяют запускать код ближе к пользователю. Не совсем “традиционные облака”, но важный кусок современного ландшафта (особенно для веб-компонентов, A/B тестов, CDN логики). DevOps используют эти сервисы для глобальных систем (например, перенести часть вычислений на край сети, разгрузив бэкэнд).

В итоге, **лучшие практики облачной инфраструктуры** на 2024: использовать *managed-сервисы там, где это возможно* (уменьшает операционные издержки – базы, кэши, очереди лучше брать как сервис, если доверяете провайдеру); внедрять *IaC для всего* (будь то CloudFormation/ARM или кросс-платформенные Terraform/Pulumi); распределять сервисы по зонам, а при необходимости – регионам (для высокой доступности); следить за *облачным бюджетом* (алерты на аномальные траты). И, конечно, держать в уме план отступления: что делать, если провайдер недоступен или тарифы изменились – т.е. иметь *облачную портативность* на уровне архитектуры (контейнеры, K8s, абстракции) и на уровне данных (резервные копии, экпорт форматов).

### Kubernetes и контейнерные платформы

**Kubernetes** за последние годы окончательно утвердился в роли “новой операционной системы” для датацентров. В 2023 более 90% опрошенных компаний, работающих с контейнерами, используют Kubernetes в той или иной форме. Для DevOps и SRE Kubernetes – основной объект управления: на нём крутятся приложения, к нему прикручиваются CI/CD, мониторинг, scaling.

**Дистрибутивы и решения на базе Kubernetes:**
- **OpenShift (Red Hat)** – enterprise-платформа, построенная на Kubernetes + множестве дополнений (операторы для баз данных, CI/CD (Tekton) в составе, сервис mesh, Registry, мониторинг). OpenShift лидирует в корпоративном сегменте (банки, госорганизации), где нужна поддержка и готовые интеграции. 2023: OpenShift 4.x продолжает править бал в этих сферах, хотя конкуренцию составляют VMware Tanzu и SUSE Rancher.
- **Rancher (SUSE)** – открытая платформа управления множеством кластеров Kubernetes, плюс свой лёгкий дистрибутив (RKE, а также k3s). Rancher удобен для гибридных облаков – единая панель для EKS/AKS/GKE и on-prem кластеров. SUSE после покупки продолжила развивать Rancher, он остаётся популярным open-source решением.
- **VMware Tanzu** – эволюция Kubernetes-стека от VMware, часто поставляется вместе с VMware vSphere (как vSphere with Tanzu). Также включает управление несколькими k8s-кластерами, сервис mesh, построен вокруг открытых компонентов (Harbor registry, Contour ingress и т.д.). Привлекателен для тех, кто уже “на VMware” и хочет контейнеры без смены экосистемы.
- **Docker Enterprise / Mirantis Kubernetes (MKS)** – Docker Inc. продала enterprise-направление Mirantis, которая развивает Kubernetes-платформу. Ниша стала узкой, т.к. Mirantis фокусируется на специфических вертикалях.
- **Canonical Charmed Kubernetes / MicroK8s** – Ubuntu предлагает свои варианты: полный Charmed K8s – для кластеров (с Juju charms), MicroK8s – для облегчённых установок. MicroK8s удобен как локально, так и для edge.
- **K3s** – упоминавшийся лёгкий Kubernetes, вырезающий неиспользуемые модули. В 2023 получил официальную сертификацию как CNCF-конформный дистрибутив. Идеален для edge и IoT, где ресурс ограничен. Например, JYSK развернул k3s на тысячах магазинов ([Unleashing the Power of k3s for Edge Computing: Deploying 3000+ in-store Kubernetes Clusters — Part 1 | by Ryan Gough | JYSK Tech](https://jysk.tech/unleashing-the-power-of-k3s-for-edge-computing-deploying-3000-in-store-kubernetes-clusters-part-77ecc5378d31#:~:text=The%20initial%20instalment%20of%20our,bolster%20our%20infrastructure%E2%80%99s%20competitive%20advantage)), благодаря компактности и простоте установки (одно бинарное).
- **Kubernetes версии и фичи:** 2023 увидел выход версий 1.25–1.28. Важные улучшения: GA Pod Security Admission (новая политика безопасности вместо PodSecurityPolicy), улучшения в StatefulSet (автоочистка орфанных Volume), API Gateway CRD (этот ещё в бете), а также много работы над производительностью контроллеров. В целом, Kubernetes стал более надёжным и безопасным по умолчанию. Best practice – своевременно обновляться (отставание больше чем на 2 версии чревато отсутствием поддержки). Также стало понятно, что **Kubernetes не панацея**: он приносит сложность, поэтому маленькие проекты могут обходиться без него (например, серверлесс или PaaS), но для средних и крупных систем его value практически неоспоримо.

**Serverless на Kubernetes:**
- **Knative** – набор компонентов, позволяющий запускать функции/контейнеры с авто-масштабированием до 0 и eventing (подписка на события). К 2024 Knative стал инкубаторским проектом CNCF. Многие устанавливают Knative на свой кластер, чтобы дать разработчикам более простой интерфейс (Functions as a Service) поверх Kubernetes. Алтернативы: **OpenFaaS**, **Kubeless**, но они менее активны сейчас.
- **KEDA** (Kubernetes Event-driven Autoscaling) – проект для масштабирования deployment’ов на основе нестандартных метрик/событий (например, длина очереди Kafka, или на сообщение в Azure Queue). Очень полезен, дополняя стандартный HPA (Horizontal Pod Autoscaler), который из коробки умеет только по CPU/Memory или кастомным метрикам из Prom. KEDA в 2023 получила широкий adoption, закрывая кейсы event-based scaling в cloud-native мире.

**Stateful на Kubernetes:** раньше Kubernetes считали только для stateless, но 2023–2024 – уже полно примеров больших stateful систем на кластерах:
- **Operators for DB**: множество операторов (Crunchy Postgres, Zalando Postgres Operator, MongoDB Operator, Cassandra Operator, Vitess for MySQL clustering) – они автоматизируют рутину (backup, failover) в Kubernetes. Best practice – использовать операторы от признанных комьюнити или вендоров, если решено держать БД внутри кластера.
- **CSI (Container Storage Interface)**: стандарт, позволивший облакам и SDS-системам (Ceph, Longhorn, etc.) интегрироваться. В 2023 почти у каждого хранилища есть CSI-драйвер. Это позволяет легко получать Persistent Volume из облачного диска, сетевого хранилища или даже NFS. Для DevOps важно задавать правильные *StorageClass* – например, SSD для БД, HDD для логов – и следить за квотами, чтобы storage не стал узким местом.

**Multi-Cluster и Federation:** Когда кластеров Kubernetes много (разные регионы, env’ы), возник вопрос – как их координировать. Проект **KubeFed** (ранее Federation v2) даёт механизм синхронизации объектов между кластерами – но не стал массовым. Сейчас чаще идут двумя путями:
1. **Уровень оркестрации выше:** системы типа Rancher, Anthos или даже FluxCD/ArgoCD, которые просто управляют конфигами на множестве кластеров.
2. **Сетевые mesh между кластерами:** например, Istio MultiMesh или Linkerd Service Mirroring – позволяют сервисам из одного кластера находить сервисы в другом. Это нужно для распределённых развертываний, DR, миграций трафика. Такие инструменты улучшились в 2023, снижая трение при работе “кластера как единицы масштаба”.

**Alternative container runtimes & WASM:** В сообществе обсуждается **WebAssembly (WASM)** как следующий шаг после контейнеров. Проекты **Krustlet**, **wasmtime**, **WasmEdge** – экспериментируют с запуском WASM-модулей в Kubernetes вместо контейнеров (CRI поддержка). В 2023 Coinbase, Adobe и др. начали пилотировать WASM для микро-сервисов: модуль загружается быстрее и более легковесен. CNCF принял проект **Wasmtime** и **runwasi**. Пока это не мейнстрим, но перспективно, особенно для edge (малый footprint) и плагинов. Возможно, 2024–2025 принесут стандартизацию WASM в K8s (через OCI support). Однако пока инфраструктурные best practice – именно контейнеры OCI.

### Edge Computing – вынос вычислений на “периферию”

**Edge computing** – концепция размещения вычислительных мощностей ближе к источникам данных или пользователям – получила дальнейшее развитие. В 2023, с распространением IoT, 5G и требованием минимальных задержек, всё больше случаев, когда выгодно обрабатывать данные локально (на “границе” сети). Лучшие практики выработались и здесь:

- **Мини-ЦОДы на локациях.** Розничные сети, промышленные предприятия устанавливают стойки или шкафы с серверами в магазинах, на заводах и т.п. Запускается там либо *плоский Kubernetes* (например, уже упомянутый K3s), либо специальные Платформы. Например, **NVIDIA Fleet Command** – для управления парком edge GPU станций (для AI inference на местах). Мы видим, что **k3s стал стандартом де-факто для edge Kubernetes** – кейс с JYSK (3000 магазинов) наглядно демонстрирует, как легковесный кластер может обеспечить локальный сервис и обработку данных ([Unleashing the Power of k3s for Edge Computing: Deploying 3000+ in-store Kubernetes Clusters — Part 1 | by Ryan Gough | JYSK Tech](https://jysk.tech/unleashing-the-power-of-k3s-for-edge-computing-deploying-3000-in-store-kubernetes-clusters-part-77ecc5378d31#:~:text=The%20initial%20instalment%20of%20our,bolster%20our%20infrastructure%E2%80%99s%20competitive%20advantage)).

- **IoT frameworks:** Для сенсоров и мелких устройств, где не поставить K8s, используют MQTT-брокеры, серверы сбора телеметрии. **Azure IoT Hub/Edge**, **AWS Greengrass** – платформы, позволяющие тянуть часть логики из облака на девайсы. Open-source: **Eclipse EdgeX Foundry** – фреймворк для промышленного IoT, **Node-RED** – инструмент для визуального программирования IoT-логики (часто работает на edge-шлюзах).

- **Связь центр-край:** Большой вопрос – как управлять тысячами edge-нод удалённо. Решения: **GitOps в связке с кластерами** (как JYSK использует FluxCD, см. ранее), **KubeEdge** (CNCF) – расширяет мастер Kubernetes на устройства: агенты на edge могут работать оффлайн, а потом синхронизироваться. Telco-компании (операторы связи) объединились с CNCF над проектом **Nephio** – для автоматизации телеком-инфры (5G) на базе Kubernetes + GitOps. Он только обретает форму.

- **Аппаратные улучшения:** Edge-устройства ограничены в ресурсах, поэтому применяются оптимизированные железки: ARM-процессоры (Raspberry Pi кластеры, NVIDIA Jetson для AI на edge), FPGA для специфических задач, *микро-ЦОДы* с жидкостным охлаждением для установки в суровых условиях. DevOps на edge должен учитывать разнообразие архитектур – multi-arch сборки ПО, кросс-компиляция и тесты на разных устройствах.

- **Безопасность edge:** Часть best practices – Zero Trust подход: каждый edge-девайс считается ненадёжным сегментом, соединения шифруются end-to-end до облака. Популярны mesh-VPN (WireGuard) или сервисные mesh, охватывающие edge. Например, **Linkerd** начали использовать от ядра до края, обеспечивая взаимную аутентификацию сервисов.

Edge – сложная, но увлекательная часть инфраструктуры. 2023 показал, что **cloud-native методологии могут успешно применяться на edge**. Kubernetes играет роль и здесь, хотя и в облегчённом виде. GitOps, контейнеры, микросервисы – всё это перекочевало на край. Разница в том, что сети менее надёжны и окружения разнообразнее, поэтому нужно больше внимания уделять автономности (автономная работа узлов при потере связи), наблюдаемости (чтобы центральная команда видела состояние тысяч устройств) и механизмам обновления (транковые развертывания прошивок, безопасное обновление без полного вывода из строя).

### Гибридные облака и мультиоблачные стратегии

**Гибридный облако** – сочетание собственного датацентра и публичного облака – остаётся реальностью для многих предприятий. Причины разные: законодательные ограничения (не все данные можно в облако), требования низкой задержки (внутри локальной сети быстрее), существующие капитальные вложения в своё железо. Лучшие практики гибридного подхода в 2023–2024:

- **Единые процессы для обоих сред.** Очень важно, чтобы разработчики и DevOps не поддерживали два разных стека. Обычно выбирают “cloud-first” инструменты и распространяют их на on-prem. Например, если все развертывания в облаке через GitOps (ArgoCD), то и в локальном кластере делаем так же; если мониторинг – Prometheus+Grafana, то собираем метрики и с облачных, и с локальных систем в одни дашборды. **Terraform** популярен как средство, единое для управления ресурсами везде: модули и для AWS, и для VMware vSphere, и для OpenStack – всё в одном репо, просто разные целевые модули. Такой унифицированный подход снижает барьер между средами.

- **Сеть и доступ:** гибрид подразумевает соединение облака с датацентром. Лучшее – **прямые каналы** (AWS DirectConnect, Azure ExpressRoute, etc.), дающие надежность и безопасность. Но также VPN используются (IPsec туннели или современный WireGuard). SRE практики включают мониторинг этих каналов, fallback (например, VPN over internet если DirectConnect падает). По безопасности – Zero Trust, VPN, использование провайдерских сервисов (AWS PrivateLink для доступа из облака к локальной API).

- **Общие идентификационные системы:** интеграция Active Directory/LDAP с облачными IAM, сквозные аккаунты – чтобы администрирование пользователей было единообразным. Azure AD стал по сути федеративным центром для многих – связывает локальные AD и SaaS.

- **Приложения на двух средах:** некоторые разворачивают один кластер Kubernetes, растянутый на on-prem и облако (например, с помощью OpenShift или Anthos). Это сложно (разные сети, latency), но для определённых сценариев (burst нагрузки в облако при заполнении локальных ресурсов) так делают. Best practice – держать всё-таки *раздельные кластеры* и обеспечивать их координацию на уровне CI/CD и DNS. Например, продакшн кластера 2: основной – локальный, резервный – в AWS, и DNS Failover между ними.

- **Multi-cloud**: расширение гибрида – не только свой ЦОД + облако, но и облако А + облако B. Как отмечалось, нечасто используют одновременно два облака равноправно. Но иногда разбивают по доменам: например, основное приложение на Azure (из-за Microsoft stack), а аналитику данных – в GCP (BigQuery). В 2023 были кейсы миграций из одного облака в другой ради оптимизации стоимости или освобождения от vendor lock-in. Основной вывод: **multi-cloud feasible, but complex** – требует абстрагироваться от сервисов уникальных для облака. Поэтому наилучший друг multi-cloud – *Kubernetes, Terraform и прочие кросс-платформенные слои*.

- **Выбор платформы для частного облака:** по опросам, многие вместо OpenStack/vSphere переходят на Kubernetes как основу частного облака. Используют K8s + виртуализацию (KubeVirt – для запуска VM внутри Kubernetes) – чтобы иметь и контейнеры, и старые VM под общим управлением. Это интересный тренд: Kubernetes становится шасси даже для VM. Проект **Harvester** (от Rancher) например – объединение KubeVirt и Longhorn storage, чтобы заменить VMWare vSphere на open-source стек.

**Контейнеры как уровень абстракции:** Multi-cloud и гибрид чаще всего реализуются по модели: “контейнеры везде, а где они крутятся – не важно”. Это действительно помогает – развернуть одинаковый Docker контейнер можно на VM в своем ЦОД, на ECS (AWS), на GKE (Google) – при условии, что окружение (напр. переменные, секреты) подготовлены. Поэтому распространено упрощение: *доставлять приложения в виде контейнеров*, а дальше каждая площадка имеет свой способ их запускать. DevOps тогда пишут адаптеры: Helm chart для кластера, Compose-файл для локального запуска, Terraform + AWS ECS task definition – для AWS. Это overhead, но таким образом приложения не привязаны только к одному провайдеру.

Подытоживая: **гибридные и мультиоблачные платформы** в 2023 стали *менее экзотичны*. Благодаря Kubernetes, Terraform, Vault и пр., инженеры оперируют сходными объектами в разных средах. Сами вендоры (AWS, Azure…) стремятся “захватить” и гибрид, предлагая свои инструменты – тут компании решают: либо полагаться на одного (например, все в Azure Arc), либо строить vendor-neutral слой (open-source + своя экспертиза). Выбор зависит от стратегии и наличия компетенций.

## Языки и фреймворки для инфраструктурного и SRE-кода

Современный инженер по инфраструктуре всё чаще занимается не только настройкой систем, но и написанием кода – скриптов, автоматизации, конфигурации. В 2023–2024 сформировался набор наиболее популярных языков и фреймворков, используемых в DevOps/SRE. Ниже рассмотрим эти языки, а также утилиты и библиотеки, облегчающие написание инфраструктурного кода.

### Языки программирования

- **Go (Golang):** Безусловный фаворит в экосистеме cloud-native. Огромное число ключевых проектов написаны на Go – Kubernetes, Docker, Terraform, Prometheus, Istio, etcd и др. Для инфраструктурного инженера знание Go стало очень желательным: оно позволяет читать исходники инструментов, писать плагины или операторов. В SRE-контексте Go привлекает своей эффективностью (собранный бинарник, минимальные зависимости) и простотой параллелизма (goroutines). Многие компании поощряют SRE писать утилиты на Go – например, боты, сервисы для автоматизации, экспортёры метрик. Go-код легко деплоить (один статический бинарник) и его производительность достаточна даже для высоконагруженных агентов. **TL;DR:** Go – новый “язык системного администрирования”, оттеснивший Perl/bash прошлых лет на второй план.

- **Python:** Прежний лидер скриптинга не сдаёт позиции. **Python** в DevOps используется обширно: написание вспомогательных сценариев, API-скриптов для облаков, glue-code между системами. Огромное преимущество – экосистема: библиотеки для AWS/GCP/Azure, Kubernetes (client-python), Ansible (на Python), Boto3, Request для HTTP – все доступны. SRE часто автоматизируют рутину на Python, потому что код быстро пишется и читается. Минус – интерпретируемый, не самый быстрый, но в эпоху, когда много чего выносится в сервисы, Python хватает. В 2023 вышел Python 3.11 с ещё более быстрой работой `async`/`await`, что полезно для IO-bound automation (например, параллельно опрашивать API). Интересно: некоторые Operator’ы для Kubernetes пишут на Python (фреймворк **Kopf** – Kubernetes Operator Python Framework), что позволяет задействовать Python-стек для задач, которые традиционно делали на Go.

- **Shell (Bash/sh):** Хотя принято считать, что bash уходит, на практике инфраструктурные люди всё равно много пишут shell-скриптов – запуска сервисов, CI-скрипты, entrypoint контейнеров и т.д. Best practice – держать их простыми и переносимыми, использовать инструменты shellcheck для отлова ошибок. Но сложные вещи (цикл опроса API, парсинг JSON) уже лучше сделать на Python/Golang.

- **JavaScript/TypeScript:** Роль этих языков в DevOps возросла благодаря инструментам, которые их используют. **Node.js** скрипты часто применяют для утилит CLI (пример – AWS CDK написан на TypeScript, cdk8s для K8s, многие HashiCorp инструменты имеют SDK для Node). **TypeScript** – строгая надстройка над JS – особенно популярен: инфраструктурные проекты Pulumi, CDK, Serverless Framework позволяют писать TS-код для управления ресурсами. Кроме того, фронтенд многих dashboard (Grafana plugins, Kubernetes dashboards) – тоже JS/TS. В SRE-коде JS встречается, например, в форме *lambdas* (AWS Lambda часто пишут на Node.js, чтобы реагировать на какие-то события). В 2023 появились *Deno Deploy* и *Cloudflare Workers* – запускающие TS/JS на edge, что тоже может использоваться SRE для небольших прокси/баков. Но в целом, для “core” инфраструктуры JS не основной язык, скорее вспомогательный.

- **Rust:** Этот язык набрал огромную популярность среди системных программистов, и начал проникать в инструменты для DevOps. **Rust** славится безопасностью (отсутствие ошибок памяти) и скоростью на уровне C. В 2023 заметны проекты: **Linkerd2-proxy** (часть service mesh Linkerd) – на Rust, **Vector** (агент сбора логов, ныне Datadog) – на Rust, **TiKV** (хранилище от TiDB) – Rust, некоторые компоненты Kubernetes (например, Argo Data Plane, kubelet-replacement проекты) экспериментируют с Rust. DevOps-специалисты пока не массово пишут на Rust, но могут сталкиваться с его экосистемой. Например, писать собственные высокопроизводительные утилиты (анализ логов, сетевые прокси). Rust пока является скорее “областью интереса” для инфраструктурных инженеров, желающих погружаться глубже. Однако его присутствие явно растёт, и возможно, через пару лет Rust станет так же обязателен, как сейчас Go.

- **Java / C# / C++:** Эти языки используются в инфраструктурных проектах реже напрямую. **Java** – основа многих enterprise-систем (Apache Kafka, Hadoop, ElasticSearch), но SRE скорее конфигурируют и мониторят их, чем пишут на Java новый код. **C#** – актуален в Azure-стеке (многие клиенты Azure используют PowerShell и C# для автоматизаций), но глобально это не тренд в DevOps (кроме как через .NET поддержка в Pulumi/CDK). **C++** – core некоторых старых систем и high-performance компонентов (например, NGINX), но для SRE задачи выбор C++ редок. Тем не менее, знание принципов ООП-языков, управление памятью – всегда полезно.

- **YAML/JSON/HCL/CUE:** Хотя это не языки программирования, а языки разметки/конфигурации, нельзя их не упомянуть, ведь **“80% работы DevOps – это писать YAML”** – шутка, близкая к истине. Конфигурационные DSL:
  - **YAML** – применяется в Kubernetes манифестах, GitHub Actions, Ansible, GitLab CI и множестве других. Главное – следить за форматированием (пробелы!) и использовать средства шаблонизации (Helm, Jinja2 в Ansible) с осторожностью. YAML-ы стали настолько объёмными, что возникли упомянутые инициативы (Cue lang) для генерации YAML из более сжатых описаний.
  - **HCL (HashiCorp Config Language)** – язык Terraform, Nomad, Consul конфигов. Выдержал годы, многим нравится читаемость. Прост, ограничен, но именно в этом его сила.
  - **JSON** – базовый формат, который часто является “посредником” (например, CloudFormation, Docker Compose v1). Его неудобно писать руками, но он легко генерируется. Сейчас YAML почти везде вытеснил JSON из ручного использования.
  - **CUE lang** – новым поколением может стать этот язык (или похожие). Cue – от Google, позволяет декларативно описывать конфиги с валидацией, типами, и на выходе получать YAML/JSON. Пока его используют в узких местах, но, возможно, DevOps будущего будут больше писать на CUE, а не на YAML прямо.

**Вывод:** инженеру инфраструктуры сегодня важно владеть как минимум одним скриптовым языком (Python, Bash) и одним компилируемым (Go, возможно Rust). Это позволяет решать широкий спектр задач – от быстрого прототипирования автоматизации до написания собственных контроллеров или плагинов. Обязательным становится умение читать и писать **YAML/JSON/HCL** – конфигурация-as-code есть везде. Также необходимо понимать **концепции парадигм**: декларативное описание (как в Kubernetes) vs императивное программирование (как Python script), event-driven (асинхронная обработка) vs procedural (последовательный). SRE-код часто носит событийный характер (например, триггер от Alertmanager запускает Python-скрипт, который в свою очередь дергает Kubernetes API).

### Фреймворки и библиотеки

Здесь подразумеваются не фреймворки в смысле веб-разработки, а утилиты и SDK, облегчающие написание инфраструктурного кода:

- **AWS SDK / Azure SDK / GCP SDK:** официальные библиотеки для управления облаком на разных языках (boto3 для Python AWS, @azure/* пакеты для JS, google-cloud-* для GCP). Они дают программистам доступ ко всем сервисам. DevOps часто пишут небольшие утилиты с ними: например, скрипт, который находит неиспользуемые ресурсы по тэгам, или который запускается по CloudWatch Event и обрабатывает автособытие. В 2023 SDK стали ещё более мощными, но и громоздкими – чтобы избежать лишнего кода, предпочитают IaC инструменты. Но знание SDK полезно для сложных интеграций.

- **Kubernetes Client Libraries:** для всех популярных языков есть клиенты к Kubernetes API (official client-go, client-python, Java client и т.д.). Они нужны, чтобы писать операторы, контроллеры, или просто скрипты, взаимодействующие с k8s. Например, *Python Kubernetes client* позволяет SRE-инженеру быстро наколенке сделать скрипт, который периодически смотрит, нет ли не рестартующих подов, и чистит их по какому-то критерию. Вообще, *операторы* – расширения k8s – обычно пишутся на **Operator SDK (Go)** или **Kubebuilder** (Go), либо на **kopf (Python)**. Эти фреймворки инкапсулируют шаблон “смотри на ресурс -> делай действие”. В 2023 также вышел **Java Operator SDK** и начался проект **DotNet Operator SDK**, но они нишевые.

- **Infrastructure as Code Frameworks:** Это, как описано, Pulumi, CDK (Cloud Development Kit) для разных облаков, Terraform CDK. Они позволяют писать обёртки вокруг декларативных описаний. Например, **cdk8s** – фреймворк от AWS для генерации Kubernetes YAML на любом языке (TS/Python/Go) – у вас есть классы Deployment, Service, и вы генерируете манифесты, а применяет потом kubectl или Argo. Подход “генерация конфигурации кодом” привлекателен, когда конфиг очень повторяемый.

- **Observability SDKs:** OpenTelemetry SDK – ключевой фреймворк для сбора телеметрии. Если SRE помогает командам внедрять трассировки, нужно владеть OTel API (для языков сервиса). Также **Prometheus client libraries** (для Go, Python, Java, etc.) – когда пишешь свой сервис/скрипт, можно добавить экспозицию метрик через эти библиотеки. Например, SRE написал утилиту, которая проверяет доступность сайта – вместо логов он может сразу публиковать метрику `availability_check_success{site="example.com"} 1` используя клиент Prometheus.

- **Config Management Libraries:** Например, **Python Dynaconf**, **Java Config** – помогают читать настройки из разных источников (env, files, Vault) – полезны в SRE-скриптах, которые должны быть гибко конфигурируемы.
  - **Python Cerberus/voluptuous** – для валидации YAML/JSON – могут применяться в toolchain (например, проверить, что YAML настроек соответствует схеме).
  - **Jinja2** – шаблонизатор, часто используется внутри Ansible, но и отдельно: SRE могут генерировать конфиги (nginx, etc) шаблонами.

- **Testing frameworks для инфраструктуры:**
  - **Terratest** (Go) – библиотека для написания тестов, которые вызывают Terraform и проверяют результат (например, поднялась ли VM). Позволяет CI-проверки инфраструктурного кода.
  - **Molecule** (Python) – фреймворк для тестирования Ansible-ролей: поднимает временную VM/контейнер, применяет роль, проверяет идемпотентность и результат.
  - **Testinfra** (Python) – позволяет писать pytest-тесты, которые подключаются по SSH/Docker к хосту и проверяют состояние (порты открыты, пакеты установлены).
  - В 2023 такие практики все еще скорее продвинутые, но набирают оборот, особенно Terratest, т.к. инфраструктура как код тоже должна иметь свои тесты.

- **Chaos libraries:** ChaosToolkit (Python) – библиотека для создания сценариев хаоса, DSL и плагины для разных платформ. Если не использовать готовые платформы типа Chaos Mesh, можно написать свои сценарии с помощью библиотек (например, вызвать AWS API чтобы выключить инстанс, затем проверить метрику – всё в одном python-скрипте). Это для тонкой кастомизации экспериментов.

- **Security & Compliance frameworks:**
  - **Open Policy Agent (OPA)** – движок Policy as Code (Rego язык), его используют для написать политики доступа/конфигурации. В DevOps его интегрируют: например, **Conftest** – проверять конфиги IaC на соответствие политикам; **Gatekeeper** – политика для Kubernetes (CNCF). OPA популярен: 2023 его взяли на вооружение для всяких проверок (например, запрещать определённые контейнеры).
  - **HashiCorp Sentinel** – альтернатива (но проприетарно для HashiCorp продуктов).
  - **Trivy, Grype** – сканеры контейнеров на уязвимости, можно интегрировать в pipelines (не фреймворк, но CLI).

- **ChatOps bots:** фреймворки, чтобы писать ботов для Slack/Teams, которые реагируют на события CI/CD или команды от пользователей. Например, **Hubot** (CoffeeScript, от GitHub), **Errbot** (Python). 2023: к ним добавились AI-интеграции (боты, которые отвечают на вопросы по документации, интегрируя ChatGPT). Пока не mainstream, но крупные SRE-команды экспериментируют с *AI-assisted Ops* (Microsoft даже анонсировал копилот для DevOps).

В совокупности, SRE-инженерам сегодня нужно быть хорошими **“generalist программистами”**: быстро освоить нужный инструмент, будь то написание простого Go-сервиса, или автомата на Python, или даже небольшой patch на open-source проекте. Сообщество активно делится библиотеками и сниппетами, так что многое можно переиспользовать. Важен подход: *каждую повторяемую ручную задачу записать и автоматизировать*. Средства для этого – любые вышеперечисленные по вкусу.

## Заключение

**Итоги 2023–2024:** Инфраструктурная инженерия, DevOps и SRE продолжили стремительное развитие, ещё сильнее распространив принципы автоматизации, декларирования и наблюдаемости. За эти годы **open-source инструменты** окончательно заняли центральное место в технологическом стеке – от управления инфраструктурой до мониторинга ([OpenTelemetry Announces General Availability | APMdigest](https://www.apmdigest.com/opentelemetry-announces-general-availability#:~:text=Open%20source%20dominance%20continues%20in,both%20technologies%20for%20the%20second)). Произошли знаковые события, такие как переход Terraform на новую лицензию и ответ сообщества (OpenTofu) ([Infrastructure as Code Landscape in 2023](https://terramate.io/rethinking-iac/infrastructure-as-code-landscape-in-2023/#:~:text=HashiCorp%20License%20Change%20%2F%20OpenTofu)), массовое признание GitOps как стандартного подхода ([GitOps goes mainstream - Flux CD boasts largest ecosystem | CNCF](https://www.cncf.io/blog/2023/12/01/gitops-goes-mainstream-flux-cd-boasts-largest-ecosystem/#:~:text=Takeaway%20%E2%80%93%20GitOps%20is%20the,Mainstream%20Standard%20in%202023)), достижение зрелости OpenTelemetry для наблюдаемости всего стека ([OpenTelemetry Announces General Availability | APMdigest](https://www.apmdigest.com/opentelemetry-announces-general-availability#:~:text=At%20KubeCon%20%2B%20CloudNativeCon%20North,0)). Эти изменения показывают, что экосистема не стоит на месте: появляются новые идеи (Platform Engineering, AIOps), экспериментальные технологии (WASM, Winglang), а привычные инструменты адаптируются к вызовам (мультиоблако, край, безопасность цепочки поставок).

**Главные акценты:** Если обобщить лучшие практики, которые актуальны сейчас:
- *Automate Everything:* инфраструктура как код, политики как код, мониторинг как код. Минимум ручных действий – максимум автоматизации и проверки в конвейере.
- *Объятие облака и Kubernetes:* даже если используете свои серверы, применяйте облачные подходы (иммутабельность, контейнеризация, self-healing оркестрация). Kubernetes стал унифицированной платформой для приложений, а облачные сервисы – основой бэкэнда. Навыки работы с ними обязательны.
- *Observability & Resilience по дизайну:* закладывать мониторинг, логирование, трассировку и отказоустойчивость на этапе проектирования, а не как пост-фактум доработки. Использовать стандарты (OpenTelemetry) и регулярно тестировать отказоустойчивость (chaos engineering, DR-тесты).
- *DevSecOps и надежность цепочки поставок:* интегрировать безопасность во всё – от управления зависимостями (сканирование образов, SBOM) до контроля доступа (Zero Trust). SRE теперь отвечает не только за uptime, но и за **безопасный uptime**.
- *Обучение и культура:* технология – это полдела, важно внедрять культуру сотрудничества Dev и Ops (DevOps mindset), обучение команды через постмортемы, общее владение качеством сервиса. SRE-принципы помогают дисциплинировать рост системы, чтобы он не вышел из-под контроля.

В 2024 году мы видим слияние ролей: DevOps-инженеры глубже уходят в надежность, а SRE – в автоматизацию и платформенное мышление. От инфраструктурных инженеров ожидается широкий набор навыков: и написать Helm-чарт, и попрофилировать приложение, и настроить GitLab pipeline, и разобраться, почему Kubernetes-под не стартует. Зато и влияние этих специалистов на успех компании велико: правильно выстроенные процессы доставки и эксплуатации дают конкурентное преимущество в скорости выпуска и стабильности сервиса.

**Перспективы:** Многие экспериментальные подходы 2023 года могут стать новым мейнстримом в ближайшие годы. Например, **генеративный AI** – уже начали использовать для помощи в анализе логов и даже написании кода инфраструктуры; возможно, скоро часть типовых задач будет решаться полуавтоматически при поддержке ML. **Полностью автономные системы** – мечта SRE – пока не достигнута, но автоскейлинг, самовосстановление и самонастройка на основе feedback-циклов явно совершенствуются. **Унификация Dev, Sec, Ops** продолжится: концепции типа *GitOps* этому способствуют, как и более тесная интеграция инструментов (например, единый dashboard от кода до метрик).

В заключение, сфера инфраструктурной инженерии и SRE остаётся одной из самых динамично развивающихся. Лучшие практики 2023–2024 отражают зрелость: мы научились эффективно строить и поддерживать сложные системы с помощью кода и автоматизации. Впереди – новые вызовы масштаба, сложности и безопасности, но опираясь на открытое сообщество и накопленные знания, команды DevOps/SRE готовы их встретить. Этот период подтвердил: **open-source и облачно-родные подходы – движущая сила инноваций**, и компании, которые их освоили, получают ощутимые выигрыши в продуктивности и надёжности своих цифровых сервисов.
